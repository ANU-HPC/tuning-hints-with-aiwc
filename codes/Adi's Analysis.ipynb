{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA C Best Practices Guide -- Shared Memory Optimisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following to run the same analysis on a different problem size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OCLGRIND=/oclgrind\n",
      "env: PROBLEM_SIZE=medium\n"
     ]
    }
   ],
   "source": [
    "%env OCLGRIND=/oclgrind\n",
    "%env PROBLEM_SIZE=medium\n",
    "#%env PROBLEM_SIZE=small\n",
    "#%env PROBLEM_SIZE=medium\n",
    "#%env PROBLEM_SIZE=large\n",
    "\n",
    "# set-up compulsory stuff\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f sbd aiwc-tester lsb.*.r0* aiwc_*.csv aiwc_*_itb.log Rplots.pdf cpu-loop-block cpu-mandelbrot-vectorization\n",
      "g++ cpu-loop-blocking.cpp -o cpu-loop-block -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ cpu-mandelbrot-vectorization.cpp -o cpu-mandelbrot-vectorization -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ aiwc-tester.cpp -o aiwc-tester -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n"
     ]
    }
   ],
   "source": [
    "! make clean\n",
    "! make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment and collect runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//shared memory in matrix multiplication ported from the [cuda c best practices guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-aa)\r\n",
      "\r\n",
      "\r\n",
      "__kernel void simpleMultiply(__global float *a,__global float *b,__global float *c, int N)\r\n",
      "{\r\n",
      "    const int globalRow = get_global_id(0); // Row ID of C (0..M)\r\n",
      "    const int globalCol = get_global_id(1); // Col ID of C (0..N)\r\n",
      " \r\n",
      "    // Compute a single element (loop over K)\r\n",
      "    float acc = 0.0f;\r\n",
      "    for (int k=0; k<N; k++) {\r\n",
      "        acc += b[k*N + globalCol] * a[globalRow*N + k];\r\n",
      "    }\r\n",
      " \r\n",
      "    // Store the result\r\n",
      "    c[globalRow*N + globalCol] = acc;\r\n",
      "}\r\n",
      "\r\n",
      "__kernel void coalescedMultiply(const __global float* A, \r\n",
      "                                const __global float* B,\r\n",
      "                                __global float* C, const int N)\r\n",
      "{\r\n",
      "    __local float aTile[TILE_DIM][TILE_DIM];\r\n",
      "\r\n",
      "    const int localRow = get_local_id(0);\r\n",
      "    const int localCol = get_local_id(1);\r\n",
      "\r\n",
      "    const int globalRow = get_global_id(0);\r\n",
      "    const int globalCol = get_global_id(1);\r\n",
      "    //int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y; //get_global_id()\r\n",
      "    //int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x; //get_global_id()\r\n",
      "    __private float sum = 0.0f;\r\n",
      "\r\n",
      "    const int numTiles = N / TILE_DIM;\r\n",
      "    for (int i = 0; i < numTiles; i++) {\r\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\r\n",
      "        aTile[localRow][localCol] = A[tiledRow];\r\n",
      "        //aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "        for (int k = 0; k < TILE_DIM; k++) {\r\n",
      "            sum += aTile[localRow][k] * B[(i*TILE_DIM+k)*N+globalCol];\r\n",
      "        }\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "        \r\n",
      "    }\r\n",
      "    C[globalRow*N+globalCol] = sum;\r\n",
      "}\r\n",
      "\r\n",
      "__kernel void sharedABMultiply(__global float *A, __global float* B, __global float *C, int N)\r\n",
      "{\r\n",
      "    __local float aTile[TILE_DIM][TILE_DIM],\r\n",
      "                  bTile[TILE_DIM][TILE_DIM];\r\n",
      "    \r\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "\r\n",
      "    const int localRow = get_local_id(0);\r\n",
      "    const int localCol = get_local_id(1);\r\n",
      "\r\n",
      "    const int globalRow = get_global_id(0);\r\n",
      "    const int globalCol = get_global_id(1);\r\n",
      "    \r\n",
      "    float sum = 0.0f;\r\n",
      "    const int numTiles = N / TILE_DIM;\r\n",
      "\r\n",
      "    for (int i = 0; i < numTiles; i++) {\r\n",
      "    //    aTile[localRow][localCol] = A[row*TILE_DIM+get_local_id(0)];\r\n",
      "    //    bTile[localRow][localCol] = B[get_local_id(1)*N+col];\r\n",
      "    //    barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\r\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\r\n",
      "        aTile[localRow][localCol] = A[tiledRow];\r\n",
      "        bTile[localCol][localRow] = B[tiledCol];\r\n",
      "\r\n",
      "        // aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\r\n",
      "        // bTile[localRow][localCol] = B[localRow + TILE_DIM*get_group_id(1) \r\n",
      "        //                             + N*(TILE_DIM*get_group_id(0) + localCol)]; // Implicit transpose\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);                \r\n",
      "        for (int k = 0; k < TILE_DIM; k++) {\r\n",
      "            sum += aTile[localRow][k]* bTile[localCol][k]; //???\r\n",
      "        }\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "    }\r\n",
      "\r\n",
      "    C[globalRow*N+globalCol] = sum;\r\n",
      "}\r\n",
      "\r\n",
      "/*\r\n",
      "OpenCL Kernels for matrix multiplicatioglobalRow*N+i*TILE_DIM + localColby Cedric Nugeteren\r\n",
      "\r\n",
      "    The MIT License (MIT)\r\n",
      "\r\n",
      "Copyright (c) 2014 SURFsara\r\n",
      "\r\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\r\n",
      "of this software and associated documentation files (the \"Software\"), to deal\r\n",
      "in the Software without restriction, including without limitation the rights\r\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n",
      "copies of the Software, and to permit persons to whom the Software is\r\n",
      "furnished to do so, subject to the following conditions:\r\n",
      "\r\n",
      "The above copyright notice and this permission notice shall be included in\r\n",
      "all copies or substantial portions of the Software.\r\n",
      "\r\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\n",
      "THE SOFTWARE.\r\n",
      "*/\r\n",
      "\r\n",
      "/*\r\n",
      "    Coalesced and tiled calculations -- splitting the M*N matrix\r\n",
      "    into several k*k workgroups and calculating smartly after\r\n",
      "    coalescing into shared memory\r\n",
      "*/\r\n",
      "//__kernel void GEMM2(__global float *a,__global float *b,__global float *c, int N)\r\n",
      "// __kernel void GEMM2(  const __global float* A,\r\n",
      "//                       const __global float* B,\r\n",
      "//                       __global float* C,\r\n",
      "//                       const int N) {\r\n",
      "    \r\n",
      "//     // Thread identifiers\r\n",
      "//     const int row = get_local_id(0); // Local row ID (max: TS)\r\n",
      "//     const int col = get_local_id(1); // Local col ID (max: TS)\r\n",
      "//     const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\r\n",
      "//     const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\r\n",
      " \r\n",
      "//     // Local memory to fit a tile of TS*TS elements of A and B\r\n",
      "//     __local float Asub[TILE_DIM][TILE_DIM];\r\n",
      "//     __local float Bsub[TILE_DIM][TILE_DIM];\r\n",
      " \r\n",
      "//     // Initialise the accumulation register\r\n",
      "//     float acc = 0.0f;\r\n",
      "    \r\n",
      "//     // Loop over all tiles\r\n",
      "//     const int numTiles = N/TILE_DIM;\r\n",
      "//     for (int t=0; t<numTiles; t++) {\r\n",
      " \r\n",
      "//         // Load one tile of A and B into local memory\r\n",
      "//         const int tiledRow = TILE_DIM*t + row;\r\n",
      "//         const int tiledCol = TILE_DIM*t + col;\r\n",
      "//         //Asub[col][row] = A[globalCol*N + tiledRow];\r\n",
      "//         //Bsub[col][row] = B[tiledCol*N + globalRow];\r\n",
      "\r\n",
      "//         Asub[col][row] = A[tiledCol*N + globalRow];\r\n",
      "//         Bsub[col][row] = B[globalCol*N + tiledRow];\r\n",
      " \r\n",
      "//         // Synchronise to make sure the tile is loaded\r\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      " \r\n",
      "//         // Perform the computation for a single tile\r\n",
      "//         for (int k=0; k<TILE_DIM; k++) {\r\n",
      "//             //acc += Asub[col][k] * Bsub[k][row];\r\n",
      "//             acc += Asub[k][row] * Bsub[col][k];\r\n",
      "\r\n",
      "//         }\r\n",
      " \r\n",
      "//         // Synchronise before loading the next tile\r\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "//     }\r\n",
      "//     // Store the final result in C32\r\n",
      "//     //C[globalCol + globalRow*N] = acc;32\r\n",
      "//     C[globalCol*N + globalRow] = acc;\r\n",
      "// }\r\n",
      "\r\n",
      "__kernel void GEMM2Multiply(const __global float* A,\r\n",
      "                      const __global float* B,\r\n",
      "                      __global float* C,\r\n",
      "                      const int N) {\r\n",
      "\r\n",
      "\r\n",
      "    const int localRow = get_local_id(0);\r\n",
      "    const int localCol = get_local_id(1);\r\n",
      "\r\n",
      "    const int globalRow = localRow + get_group_id(0) * get_local_size(0);\r\n",
      "    const int globalCol = localCol + get_group_id(1) * get_local_size(1);\r\n",
      "\r\n",
      "    __local float ASub[TILE_DIM][TILE_DIM];\r\n",
      "    __local float BSub[TILE_DIM][TILE_DIM];\r\n",
      "\r\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "\r\n",
      "    float acc = 0.0f;\r\n",
      "\r\n",
      "    const int numTiles = N/TILE_DIM;\r\n",
      "    for (int i = 0; i < numTiles; i++) {\r\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\r\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\r\n",
      "        ASub[localRow][localCol] = A[tiledRow];\r\n",
      "        BSub[localRow][localCol] = B[tiledCol];\r\n",
      "\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "    \r\n",
      "        for (int k=0; k<TILE_DIM; k++) {\r\n",
      "            //acc += Asub[col][k] * Bsub[k][row];\r\n",
      "            acc += ASub[localRow][k] * BSub[k][localCol];\r\n",
      "        }\r\n",
      "\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "    }\r\n",
      "    C[globalRow*N + globalCol] = acc;\r\n",
      "}\r\n",
      "\r\n",
      "/*\r\n",
      "__kernel void GEMM2(const int M, const int N, const int K,\r\n",
      "                      const __global float* A,\r\n",
      "                      const __global float* B,\r\n",
      "                      __global float* C) {\r\n",
      "    \r\n",
      "    // Thread identifiers\r\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\r\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS)\r\n",
      "    const int globalRow = TS*get_group_id(0) + row; // Row ID of C (0..M)\r\n",
      "    const int globalCol = TS*get_group_id(1) + col; // Col ID of C (0..N)\r\n",
      " \r\n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\r\n",
      "    __local float Asub[TS][TS];\r\n",
      "    __local float Bsub[TS][TS];\r\n",
      " \r\n",
      "    // Initialise the accumulation register\r\n",
      "    float acc = 0.0f;\r\n",
      "    \r\n",
      "    // Loop over all tiles\r\n",
      "    const int numTiles = K/TS;\r\n",
      "    for (int t=0; t<numTiles; t++) {\r\n",
      " \r\n",
      "        // Load one tile of A and B into local memory\r\n",
      "        const int tiledRow = TS*t + row;\r\n",
      "        const int tiledCol = TS*t + col;\r\n",
      "        Asub[col][row] = A[tiledCol*M + globalRow];\r\n",
      "        Bsub[col][row] = B[globalCol*K + tiledRow];\r\n",
      " \r\n",
      "        // Synchronise to make sure the tile is loaded\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      " \r\n",
      "        // Perform the computation for a single tile\r\n",
      "        for (int k=0; k<TS; k++) {\r\n",
      "            acc += Asub[k][row] * Bsub[col][k];\r\n",
      "        }\r\n",
      " \r\n",
      "        // Synchronise before loading the next tile\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "    }\r\n",
      " \r\n",
      "    // Store the final result in C\r\n",
      "    C[glo\r\n",
      "*/\r\n",
      "\r\n",
      "\r\n",
      "/*\r\n",
      "    More work per thread: by factor WPT.\r\n",
      "*/\r\n",
      "/*\r\n",
      "__kernel void myGEMM3(const __global float* A,\r\n",
      "                      const __global float* B,\r\n",
      "                      __global float* C, const int N) {\r\n",
      "    \r\n",
      "    // Thread identifiers\r\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\r\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS/WPT == RTS)\r\n",
      "    const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\r\n",
      "    const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\r\n",
      " \r\n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\r\n",
      "    __local float Asub[TILE_DIM][TILE_DIM];\r\n",
      "    __local float Bsub[TILE_DIM][TILE_DIM];\r\n",
      " \r\n",
      "    // Initialise the accumulation registers\r\n",
      "    float acc[WPT];\r\n",
      "    for (int w=0; w<WPT; w++) {\r\n",
      "        acc[w] = 0.0f;\r\n",
      "    }\r\n",
      "    \r\n",
      "    // Loop over all tiles\r\n",
      "    const int numTiles = N/TILE_DIM;\r\n",
      "    for (int t=0; t<numTiles; t++) {\r\n",
      " \r\n",
      "        // Load one tile of A and B into local memory\r\n",
      "        for (int w=0; w<WPT; w++) {\r\n",
      "            const int tiledRow = TILE_DIM*t + row;\r\n",
      "            const int tiledCol = T*t + col;\r\n",
      "            Asub[col + w*RTS][row] = A[(tiledCol + w*RTS)*M + globalRow];\r\n",
      "            Bsub[col + w*RTS][row] = B[(globalCol + w*RTS)*K + tiledRow];\r\n",
      "        }\r\n",
      "        \r\n",
      "        // Synchronise to make sure the tile is loaded\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      " \r\n",
      "        // Perform the computation for a single tile\r\n",
      "        for (int k=0; k<TS; k++) {\r\n",
      "            for (int w=0; w<WPT; w++) {\r\n",
      "                acc[w] += Asub[k][row] * Bsub[col + w*RTS][k];\r\n",
      "            }\r\n",
      "        }\r\n",
      " \r\n",
      "        // Synchronise before loading the next tile\r\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\r\n",
      "    }\r\n",
      " \r\n",
      "    // Store the final results in C\r\n",
      "    for (int w=0; w<WPT; w++) {\r\n",
      "        C[(globalCol + w*RTS)*M + globalRow] = acc[w];\r\n",
      "    }\r\n",
      "}\r\n",
      "*/\r\n",
      "\r\n",
      "/*\r\n",
      "Wider data access instructions\r\n",
      "*/"
     ]
    }
   ],
   "source": [
    "! cat ./gpu-strided-global-memory-access-unoptimised.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** LSB_Init >gpu_memory_access< writing to >lsb.gpu_memory_access.r0< *****\n",
      "Attempting kernel: ./gpu-strided-global-memory-access-unoptimised.cl with contents:\n",
      "//shared memory in matrix multiplication ported from the [cuda c best practices guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-aa)\n",
      "\n",
      "\n",
      "__kernel void simpleMultiply(__global float *a,__global float *b,__global float *c, int N)\n",
      "{\n",
      "    const int globalRow = get_global_id(0); // Row ID of C (0..M)\n",
      "    const int globalCol = get_global_id(1); // Col ID of C (0..N)\n",
      " \n",
      "    // Compute a single element (loop over K)\n",
      "    float acc = 0.0f;\n",
      "    for (int k=0; k<N; k++) {\n",
      "        acc += b[k*N + globalCol] * a[globalRow*N + k];\n",
      "    }\n",
      " \n",
      "    // Store the result\n",
      "    c[globalRow*N + globalCol] = acc;\n",
      "}\n",
      "\n",
      "__kernel void coalescedMultiply(const __global float* A, \n",
      "                                const __global float* B,\n",
      "                                __global float* C, const int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = get_global_id(0);\n",
      "    const int globalCol = get_global_id(1);\n",
      "    //int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y; //get_global_id()\n",
      "    //int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x; //get_global_id()\n",
      "    __private float sum = 0.0f;\n",
      "\n",
      "    const int numTiles = N / TILE_DIM;\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        aTile[localRow][localCol] = A[tiledRow];\n",
      "        //aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        for (int k = 0; k < TILE_DIM; k++) {\n",
      "            sum += aTile[localRow][k] * B[(i*TILE_DIM+k)*N+globalCol];\n",
      "        }\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        \n",
      "    }\n",
      "    C[globalRow*N+globalCol] = sum;\n",
      "}\n",
      "\n",
      "__kernel void sharedABMultiply(__global float *A, __global float* B, __global float *C, int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM],\n",
      "                  bTile[TILE_DIM][TILE_DIM];\n",
      "    \n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = get_global_id(0);\n",
      "    const int globalCol = get_global_id(1);\n",
      "    \n",
      "    float sum = 0.0f;\n",
      "    const int numTiles = N / TILE_DIM;\n",
      "\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "    //    aTile[localRow][localCol] = A[row*TILE_DIM+get_local_id(0)];\n",
      "    //    bTile[localRow][localCol] = B[get_local_id(1)*N+col];\n",
      "    //    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\n",
      "        aTile[localRow][localCol] = A[tiledRow];\n",
      "        bTile[localCol][localRow] = B[tiledCol];\n",
      "\n",
      "        // aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\n",
      "        // bTile[localRow][localCol] = B[localRow + TILE_DIM*get_group_id(1) \n",
      "        //                             + N*(TILE_DIM*get_group_id(0) + localCol)]; // Implicit transpose\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);                \n",
      "        for (int k = 0; k < TILE_DIM; k++) {\n",
      "            sum += aTile[localRow][k]* bTile[localCol][k]; //???\n",
      "        }\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      "\n",
      "    C[globalRow*N+globalCol] = sum;\n",
      "}\n",
      "\n",
      "/*\n",
      "OpenCL Kernels for matrix multiplicatioglobalRow*N+i*TILE_DIM + localColby Cedric Nugeteren\n",
      "\n",
      "    The MIT License (MIT)\n",
      "\n",
      "Copyright (c) 2014 SURFsara\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in\n",
      "all copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
      "THE SOFTWARE.\n",
      "*/\n",
      "\n",
      "/*\n",
      "    Coalesced and tiled calculations -- splitting the M*N matrix\n",
      "    into several k*k workgroups and calculating smartly after\n",
      "    coalescing into shared memory\n",
      "*/\n",
      "//__kernel void GEMM2(__global float *a,__global float *b,__global float *c, int N)\n",
      "// __kernel void GEMM2(  const __global float* A,\n",
      "//                       const __global float* B,\n",
      "//                       __global float* C,\n",
      "//                       const int N) {\n",
      "    \n",
      "//     // Thread identifiers\n",
      "//     const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "//     const int col = get_local_id(1); // Local col ID (max: TS)\n",
      "//     const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "//     const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "//     // Local memory to fit a tile of TS*TS elements of A and B\n",
      "//     __local float Asub[TILE_DIM][TILE_DIM];\n",
      "//     __local float Bsub[TILE_DIM][TILE_DIM];\n",
      " \n",
      "//     // Initialise the accumulation register\n",
      "//     float acc = 0.0f;\n",
      "    \n",
      "//     // Loop over all tiles\n",
      "//     const int numTiles = N/TILE_DIM;\n",
      "//     for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "//         // Load one tile of A and B into local memory\n",
      "//         const int tiledRow = TILE_DIM*t + row;\n",
      "//         const int tiledCol = TILE_DIM*t + col;\n",
      "//         //Asub[col][row] = A[globalCol*N + tiledRow];\n",
      "//         //Bsub[col][row] = B[tiledCol*N + globalRow];\n",
      "\n",
      "//         Asub[col][row] = A[tiledCol*N + globalRow];\n",
      "//         Bsub[col][row] = B[globalCol*N + tiledRow];\n",
      " \n",
      "//         // Synchronise to make sure the tile is loaded\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "//         // Perform the computation for a single tile\n",
      "//         for (int k=0; k<TILE_DIM; k++) {\n",
      "//             //acc += Asub[col][k] * Bsub[k][row];\n",
      "//             acc += Asub[k][row] * Bsub[col][k];\n",
      "\n",
      "//         }\n",
      " \n",
      "//         // Synchronise before loading the next tile\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\n",
      "//     }\n",
      "//     // Store the final result in C32\n",
      "//     //C[globalCol + globalRow*N] = acc;32\n",
      "//     C[globalCol*N + globalRow] = acc;\n",
      "// }\n",
      "\n",
      "__kernel void GEMM2Multiply(const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C,\n",
      "                      const int N) {\n",
      "\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = localRow + get_group_id(0) * get_local_size(0);\n",
      "    const int globalCol = localCol + get_group_id(1) * get_local_size(1);\n",
      "\n",
      "    __local float ASub[TILE_DIM][TILE_DIM];\n",
      "    __local float BSub[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    float acc = 0.0f;\n",
      "\n",
      "    const int numTiles = N/TILE_DIM;\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\n",
      "        ASub[localRow][localCol] = A[tiledRow];\n",
      "        BSub[localRow][localCol] = B[tiledCol];\n",
      "\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    \n",
      "        for (int k=0; k<TILE_DIM; k++) {\n",
      "            //acc += Asub[col][k] * Bsub[k][row];\n",
      "            acc += ASub[localRow][k] * BSub[k][localCol];\n",
      "        }\n",
      "\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      "    C[globalRow*N + globalCol] = acc;\n",
      "}\n",
      "\n",
      "/*\n",
      "__kernel void GEMM2(const int M, const int N, const int K,\n",
      "                      const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C) {\n",
      "    \n",
      "    // Thread identifiers\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS)\n",
      "    const int globalRow = TS*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "    const int globalCol = TS*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\n",
      "    __local float Asub[TS][TS];\n",
      "    __local float Bsub[TS][TS];\n",
      " \n",
      "    // Initialise the accumulation register\n",
      "    float acc = 0.0f;\n",
      "    \n",
      "    // Loop over all tiles\n",
      "    const int numTiles = K/TS;\n",
      "    for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "        // Load one tile of A and B into local memory\n",
      "        const int tiledRow = TS*t + row;\n",
      "        const int tiledCol = TS*t + col;\n",
      "        Asub[col][row] = A[tiledCol*M + globalRow];\n",
      "        Bsub[col][row] = B[globalCol*K + tiledRow];\n",
      " \n",
      "        // Synchronise to make sure the tile is loaded\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "        // Perform the computation for a single tile\n",
      "        for (int k=0; k<TS; k++) {\n",
      "            acc += Asub[k][row] * Bsub[col][k];\n",
      "        }\n",
      " \n",
      "        // Synchronise before loading the next tile\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      " \n",
      "    // Store the final result in C\n",
      "    C[glo\n",
      "*/\n",
      "\n",
      "\n",
      "/*\n",
      "    More work per thread: by factor WPT.\n",
      "*/\n",
      "/*\n",
      "__kernel void myGEMM3(const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C, const int N) {\n",
      "    \n",
      "    // Thread identifiers\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS/WPT == RTS)\n",
      "    const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "    const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\n",
      "    __local float Asub[TILE_DIM][TILE_DIM];\n",
      "    __local float Bsub[TILE_DIM][TILE_DIM];\n",
      " \n",
      "    // Initialise the accumulation registers\n",
      "    float acc[WPT];\n",
      "    for (int w=0; w<WPT; w++) {\n",
      "        acc[w] = 0.0f;\n",
      "    }\n",
      "    \n",
      "    // Loop over all tiles\n",
      "    const int numTiles = N/TILE_DIM;\n",
      "    for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "        // Load one tile of A and B into local memory\n",
      "        for (int w=0; w<WPT; w++) {\n",
      "            const int tiledRow = TILE_DIM*t + row;\n",
      "            const int tiledCol = T*t + col;\n",
      "            Asub[col + w*RTS][row] = A[(tiledCol + w*RTS)*M + globalRow];\n",
      "            Bsub[col + w*RTS][row] = B[(globalCol + w*RTS)*K + tiledRow];\n",
      "        }\n",
      "        \n",
      "        // Synchronise to make sure the tile is loaded\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "        // Perform the computation for a single tile\n",
      "        for (int k=0; k<TS; k++) {\n",
      "            for (int w=0; w<WPT; w++) {\n",
      "                acc[w] += Asub[k][row] * Bsub[col + w*RTS][k];\n",
      "            }\n",
      "        }\n",
      " \n",
      "        // Synchronise before loading the next tile\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      " \n",
      "    // Store the final results in C\n",
      "    for (int w=0; w<WPT; w++) {\n",
      "        C[(globalCol + w*RTS)*M + globalRow] = acc[w];\n",
      "    }\n",
      "}\n",
      "*/\n",
      "\n",
      "/*\n",
      "Wider data access instructions\n",
      "*/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1408 N = 1408 total KiB = 23232\n",
      "Operating on a 1408x1408 matrix with a tile size 32...\n",
      "******* LSB_Finalize *******\n"
     ]
    }
   ],
   "source": [
    "! ./gpu-stride ./gpu-strided-global-memory-access-unoptimised.cl $PROBLEM_SIZE 0 1 runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse runtimes data -- to ensure the OpenCL port of the cuda codes matches those shown in CUDA code-book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     problem_size          kernel                        region  id  \\\n",
      "0          medium        none_yet               host_side_setup   0   \n",
      "1          medium        none_yet               kernel_creation   0   \n",
      "2          medium        none_yet      device_side_buffer_setup   0   \n",
      "3          medium  simpleMultiply  host_side_initialise_buffers   0   \n",
      "4          medium  simpleMultiply          device_side_h2d_copy   0   \n",
      "5          medium  simpleMultiply         simpleMultiply_kernel   0   \n",
      "6          medium  simpleMultiply          device_side_d2h_copy   0   \n",
      "7          medium  simpleMultiply  host_side_initialise_buffers   1   \n",
      "8          medium  simpleMultiply          device_side_h2d_copy   1   \n",
      "9          medium  simpleMultiply         simpleMultiply_kernel   1   \n",
      "10         medium  simpleMultiply          device_side_d2h_copy   1   \n",
      "11         medium  simpleMultiply  host_side_initialise_buffers   2   \n",
      "12         medium  simpleMultiply          device_side_h2d_copy   2   \n",
      "13         medium  simpleMultiply         simpleMultiply_kernel   2   \n",
      "14         medium  simpleMultiply          device_side_d2h_copy   2   \n",
      "15         medium  simpleMultiply  host_side_initialise_buffers   3   \n",
      "16         medium  simpleMultiply          device_side_h2d_copy   3   \n",
      "17         medium  simpleMultiply         simpleMultiply_kernel   3   \n",
      "18         medium  simpleMultiply          device_side_d2h_copy   3   \n",
      "19         medium  simpleMultiply  host_side_initialise_buffers   4   \n",
      "20         medium  simpleMultiply          device_side_h2d_copy   4   \n",
      "21         medium  simpleMultiply         simpleMultiply_kernel   4   \n",
      "22         medium  simpleMultiply          device_side_d2h_copy   4   \n",
      "23         medium  simpleMultiply  host_side_initialise_buffers   5   \n",
      "24         medium  simpleMultiply          device_side_h2d_copy   5   \n",
      "25         medium  simpleMultiply         simpleMultiply_kernel   5   \n",
      "26         medium  simpleMultiply          device_side_d2h_copy   5   \n",
      "27         medium  simpleMultiply  host_side_initialise_buffers   6   \n",
      "28         medium  simpleMultiply          device_side_h2d_copy   6   \n",
      "29         medium  simpleMultiply         simpleMultiply_kernel   6   \n",
      "...           ...             ...                           ...  ..   \n",
      "1573       medium   GEMM2Multiply          GEMM2Multiply_kernel  92   \n",
      "1574       medium   GEMM2Multiply          device_side_d2h_copy  92   \n",
      "1575       medium   GEMM2Multiply  host_side_initialise_buffers  93   \n",
      "1576       medium   GEMM2Multiply          device_side_h2d_copy  93   \n",
      "1577       medium   GEMM2Multiply          GEMM2Multiply_kernel  93   \n",
      "1578       medium   GEMM2Multiply          device_side_d2h_copy  93   \n",
      "1579       medium   GEMM2Multiply  host_side_initialise_buffers  94   \n",
      "1580       medium   GEMM2Multiply          device_side_h2d_copy  94   \n",
      "1581       medium   GEMM2Multiply          GEMM2Multiply_kernel  94   \n",
      "1582       medium   GEMM2Multiply          device_side_d2h_copy  94   \n",
      "1583       medium   GEMM2Multiply  host_side_initialise_buffers  95   \n",
      "1584       medium   GEMM2Multiply          device_side_h2d_copy  95   \n",
      "1585       medium   GEMM2Multiply          GEMM2Multiply_kernel  95   \n",
      "1586       medium   GEMM2Multiply          device_side_d2h_copy  95   \n",
      "1587       medium   GEMM2Multiply  host_side_initialise_buffers  96   \n",
      "1588       medium   GEMM2Multiply          device_side_h2d_copy  96   \n",
      "1589       medium   GEMM2Multiply          GEMM2Multiply_kernel  96   \n",
      "1590       medium   GEMM2Multiply          device_side_d2h_copy  96   \n",
      "1591       medium   GEMM2Multiply  host_side_initialise_buffers  97   \n",
      "1592       medium   GEMM2Multiply          device_side_h2d_copy  97   \n",
      "1593       medium   GEMM2Multiply          GEMM2Multiply_kernel  97   \n",
      "1594       medium   GEMM2Multiply          device_side_d2h_copy  97   \n",
      "1595       medium   GEMM2Multiply  host_side_initialise_buffers  98   \n",
      "1596       medium   GEMM2Multiply          device_side_h2d_copy  98   \n",
      "1597       medium   GEMM2Multiply          GEMM2Multiply_kernel  98   \n",
      "1598       medium   GEMM2Multiply          device_side_d2h_copy  98   \n",
      "1599       medium   GEMM2Multiply  host_side_initialise_buffers  99   \n",
      "1600       medium   GEMM2Multiply          device_side_h2d_copy  99   \n",
      "1601       medium   GEMM2Multiply          GEMM2Multiply_kernel  99   \n",
      "1602       medium   GEMM2Multiply          device_side_d2h_copy  99   \n",
      "\n",
      "              time  overhead  \n",
      "0     2.041241e+05         0  \n",
      "1     1.785518e+03         0  \n",
      "2     1.368604e+04         0  \n",
      "3     2.217114e+05         0  \n",
      "4     5.497150e+03         0  \n",
      "5     7.239936e+04         0  \n",
      "6     4.122023e+03         0  \n",
      "7     1.206977e+07         2  \n",
      "8     5.135814e+03         2  \n",
      "9     7.239825e+04         0  \n",
      "10    4.436252e+03         0  \n",
      "11    1.217111e+07         2  \n",
      "12    4.999215e+03         0  \n",
      "13    6.838098e+04         0  \n",
      "14    4.598062e+03         0  \n",
      "15    1.213714e+07         2  \n",
      "16    5.045500e+03         0  \n",
      "17    6.851985e+04         0  \n",
      "18    4.083414e+03         0  \n",
      "19    1.206765e+07         0  \n",
      "20    4.989963e+03         0  \n",
      "21    7.223758e+04         0  \n",
      "22    4.123736e+03         0  \n",
      "23    1.215632e+07         0  \n",
      "24    5.147750e+03         0  \n",
      "25    6.834406e+04         0  \n",
      "26    4.683584e+03         0  \n",
      "27    1.200198e+07         0  \n",
      "28    5.075754e+03         0  \n",
      "29    6.849728e+04         0  \n",
      "...            ...       ...  \n",
      "1573  1.628057e+04         0  \n",
      "1574  4.267422e+03         0  \n",
      "1575  1.204157e+07         0  \n",
      "1576  4.936652e+03         0  \n",
      "1577  1.626899e+04         0  \n",
      "1578  4.079324e+03         0  \n",
      "1579  1.205217e+07         0  \n",
      "1580  4.922955e+03         0  \n",
      "1581  1.626724e+04         0  \n",
      "1582  4.101664e+03         0  \n",
      "1583  1.200704e+07         0  \n",
      "1584  4.932775e+03         0  \n",
      "1585  1.627266e+04         0  \n",
      "1586  4.057238e+03         0  \n",
      "1587  1.180115e+07         0  \n",
      "1588  4.943867e+03         0  \n",
      "1589  1.627397e+04         0  \n",
      "1590  3.969430e+03         0  \n",
      "1591  1.181175e+07         0  \n",
      "1592  4.913729e+03         0  \n",
      "1593  1.627730e+04         0  \n",
      "1594  4.221303e+03         0  \n",
      "1595  1.181915e+07         3  \n",
      "1596  5.035105e+03         0  \n",
      "1597  1.628458e+04         0  \n",
      "1598  4.242633e+03         0  \n",
      "1599  1.180823e+07         0  \n",
      "1600  4.909773e+03         0  \n",
      "1601  1.626848e+04         0  \n",
      "1602  4.036977e+03         0  \n",
      "\n",
      "[1603 rows x 6 columns]\n",
      "     problem_size            kernel                   region  id  \\\n",
      "5          medium    simpleMultiply    simpleMultiply_kernel   0   \n",
      "9          medium    simpleMultiply    simpleMultiply_kernel   1   \n",
      "13         medium    simpleMultiply    simpleMultiply_kernel   2   \n",
      "17         medium    simpleMultiply    simpleMultiply_kernel   3   \n",
      "21         medium    simpleMultiply    simpleMultiply_kernel   4   \n",
      "25         medium    simpleMultiply    simpleMultiply_kernel   5   \n",
      "29         medium    simpleMultiply    simpleMultiply_kernel   6   \n",
      "33         medium    simpleMultiply    simpleMultiply_kernel   7   \n",
      "37         medium    simpleMultiply    simpleMultiply_kernel   8   \n",
      "41         medium    simpleMultiply    simpleMultiply_kernel   9   \n",
      "45         medium    simpleMultiply    simpleMultiply_kernel  10   \n",
      "49         medium    simpleMultiply    simpleMultiply_kernel  11   \n",
      "53         medium    simpleMultiply    simpleMultiply_kernel  12   \n",
      "57         medium    simpleMultiply    simpleMultiply_kernel  13   \n",
      "61         medium    simpleMultiply    simpleMultiply_kernel  14   \n",
      "65         medium    simpleMultiply    simpleMultiply_kernel  15   \n",
      "69         medium    simpleMultiply    simpleMultiply_kernel  16   \n",
      "73         medium    simpleMultiply    simpleMultiply_kernel  17   \n",
      "77         medium    simpleMultiply    simpleMultiply_kernel  18   \n",
      "81         medium    simpleMultiply    simpleMultiply_kernel  19   \n",
      "85         medium    simpleMultiply    simpleMultiply_kernel  20   \n",
      "89         medium    simpleMultiply    simpleMultiply_kernel  21   \n",
      "93         medium    simpleMultiply    simpleMultiply_kernel  22   \n",
      "97         medium    simpleMultiply    simpleMultiply_kernel  23   \n",
      "101        medium    simpleMultiply    simpleMultiply_kernel  24   \n",
      "105        medium    simpleMultiply    simpleMultiply_kernel  25   \n",
      "109        medium    simpleMultiply    simpleMultiply_kernel  26   \n",
      "113        medium    simpleMultiply    simpleMultiply_kernel  27   \n",
      "117        medium    simpleMultiply    simpleMultiply_kernel  28   \n",
      "121        medium    simpleMultiply    simpleMultiply_kernel  29   \n",
      "...           ...               ...                      ...  ..   \n",
      "1085       medium  sharedABMultiply  sharedABMultiply_kernel  70   \n",
      "1089       medium  sharedABMultiply  sharedABMultiply_kernel  71   \n",
      "1093       medium  sharedABMultiply  sharedABMultiply_kernel  72   \n",
      "1097       medium  sharedABMultiply  sharedABMultiply_kernel  73   \n",
      "1101       medium  sharedABMultiply  sharedABMultiply_kernel  74   \n",
      "1105       medium  sharedABMultiply  sharedABMultiply_kernel  75   \n",
      "1109       medium  sharedABMultiply  sharedABMultiply_kernel  76   \n",
      "1113       medium  sharedABMultiply  sharedABMultiply_kernel  77   \n",
      "1117       medium  sharedABMultiply  sharedABMultiply_kernel  78   \n",
      "1121       medium  sharedABMultiply  sharedABMultiply_kernel  79   \n",
      "1125       medium  sharedABMultiply  sharedABMultiply_kernel  80   \n",
      "1129       medium  sharedABMultiply  sharedABMultiply_kernel  81   \n",
      "1133       medium  sharedABMultiply  sharedABMultiply_kernel  82   \n",
      "1137       medium  sharedABMultiply  sharedABMultiply_kernel  83   \n",
      "1141       medium  sharedABMultiply  sharedABMultiply_kernel  84   \n",
      "1145       medium  sharedABMultiply  sharedABMultiply_kernel  85   \n",
      "1149       medium  sharedABMultiply  sharedABMultiply_kernel  86   \n",
      "1153       medium  sharedABMultiply  sharedABMultiply_kernel  87   \n",
      "1157       medium  sharedABMultiply  sharedABMultiply_kernel  88   \n",
      "1161       medium  sharedABMultiply  sharedABMultiply_kernel  89   \n",
      "1165       medium  sharedABMultiply  sharedABMultiply_kernel  90   \n",
      "1169       medium  sharedABMultiply  sharedABMultiply_kernel  91   \n",
      "1173       medium  sharedABMultiply  sharedABMultiply_kernel  92   \n",
      "1177       medium  sharedABMultiply  sharedABMultiply_kernel  93   \n",
      "1181       medium  sharedABMultiply  sharedABMultiply_kernel  94   \n",
      "1185       medium  sharedABMultiply  sharedABMultiply_kernel  95   \n",
      "1189       medium  sharedABMultiply  sharedABMultiply_kernel  96   \n",
      "1193       medium  sharedABMultiply  sharedABMultiply_kernel  97   \n",
      "1197       medium  sharedABMultiply  sharedABMultiply_kernel  98   \n",
      "1201       medium  sharedABMultiply  sharedABMultiply_kernel  99   \n",
      "\n",
      "              time  overhead  \n",
      "5     72399.361328         0  \n",
      "9     72398.248047         0  \n",
      "13    68380.984375         0  \n",
      "17    68519.853516         0  \n",
      "21    72237.582031         0  \n",
      "25    68344.060547         0  \n",
      "29    68497.281250         0  \n",
      "33    68485.623047         0  \n",
      "37    72455.656250         0  \n",
      "41    68424.181641         0  \n",
      "45    68523.085938         0  \n",
      "49    68454.501953         0  \n",
      "53    72356.667969         0  \n",
      "57    68956.085938         0  \n",
      "61    68238.927734         0  \n",
      "65    68449.511719         0  \n",
      "69    72611.628906         0  \n",
      "73    72161.894531         0  \n",
      "77    72204.453125         0  \n",
      "81    72626.972656         0  \n",
      "85    72016.660156         0  \n",
      "89    68477.324219         0  \n",
      "93    68706.392578         0  \n",
      "97    68928.845703         0  \n",
      "101   72659.052734         0  \n",
      "105   72620.203125         0  \n",
      "109   68401.785156         0  \n",
      "113   68577.810547         0  \n",
      "117   72013.810547         0  \n",
      "121   68406.966797         0  \n",
      "...            ...       ...  \n",
      "1085  14741.384766         0  \n",
      "1089  14586.457031         0  \n",
      "1093  14568.060547         0  \n",
      "1097  14574.896484         0  \n",
      "1101  14574.470703         0  \n",
      "1105  14584.564453         0  \n",
      "1109  14569.654297         0  \n",
      "1113  14578.781250         0  \n",
      "1117  14574.105469         0  \n",
      "1121  14561.609375         0  \n",
      "1125  14590.416016         0  \n",
      "1129  14575.242188         0  \n",
      "1133  14576.115234         0  \n",
      "1137  14576.011719         0  \n",
      "1141  14653.912109         0  \n",
      "1145  14573.101562         0  \n",
      "1149  14668.839844         0  \n",
      "1153  14584.921875         0  \n",
      "1157  14566.396484         6  \n",
      "1161  14584.544922         0  \n",
      "1165  14585.482422         0  \n",
      "1169  14585.824219         0  \n",
      "1173  14582.826172         0  \n",
      "1177  14572.306641         0  \n",
      "1181  14665.214844         0  \n",
      "1185  14575.285156         0  \n",
      "1189  14573.296875         0  \n",
      "1193  14585.906250         0  \n",
      "1197  14568.683594         0  \n",
      "1201  14712.166016         0  \n",
      "\n",
      "[300 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv('lsb.gpu_memory_access.r0', comment='#', sep=\"\\s+\")\n",
    "print(x)\n",
    "\n",
    "y = x[(x.region == 'simpleMultiply_kernel') | (x.region == 'coalescedMultiply_kernel') | (x.region == 'sharedABMultiply_kernel')] # | x.region == ('GEMM2Multiply_kernel')]\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     problem_size            kernel                   region  id  \\\n",
      "5          medium    simpleMultiply    simpleMultiply_kernel   0   \n",
      "9          medium    simpleMultiply    simpleMultiply_kernel   1   \n",
      "13         medium    simpleMultiply    simpleMultiply_kernel   2   \n",
      "17         medium    simpleMultiply    simpleMultiply_kernel   3   \n",
      "21         medium    simpleMultiply    simpleMultiply_kernel   4   \n",
      "25         medium    simpleMultiply    simpleMultiply_kernel   5   \n",
      "29         medium    simpleMultiply    simpleMultiply_kernel   6   \n",
      "33         medium    simpleMultiply    simpleMultiply_kernel   7   \n",
      "37         medium    simpleMultiply    simpleMultiply_kernel   8   \n",
      "41         medium    simpleMultiply    simpleMultiply_kernel   9   \n",
      "45         medium    simpleMultiply    simpleMultiply_kernel  10   \n",
      "49         medium    simpleMultiply    simpleMultiply_kernel  11   \n",
      "53         medium    simpleMultiply    simpleMultiply_kernel  12   \n",
      "57         medium    simpleMultiply    simpleMultiply_kernel  13   \n",
      "61         medium    simpleMultiply    simpleMultiply_kernel  14   \n",
      "65         medium    simpleMultiply    simpleMultiply_kernel  15   \n",
      "69         medium    simpleMultiply    simpleMultiply_kernel  16   \n",
      "73         medium    simpleMultiply    simpleMultiply_kernel  17   \n",
      "77         medium    simpleMultiply    simpleMultiply_kernel  18   \n",
      "81         medium    simpleMultiply    simpleMultiply_kernel  19   \n",
      "85         medium    simpleMultiply    simpleMultiply_kernel  20   \n",
      "89         medium    simpleMultiply    simpleMultiply_kernel  21   \n",
      "93         medium    simpleMultiply    simpleMultiply_kernel  22   \n",
      "97         medium    simpleMultiply    simpleMultiply_kernel  23   \n",
      "101        medium    simpleMultiply    simpleMultiply_kernel  24   \n",
      "105        medium    simpleMultiply    simpleMultiply_kernel  25   \n",
      "109        medium    simpleMultiply    simpleMultiply_kernel  26   \n",
      "113        medium    simpleMultiply    simpleMultiply_kernel  27   \n",
      "117        medium    simpleMultiply    simpleMultiply_kernel  28   \n",
      "121        medium    simpleMultiply    simpleMultiply_kernel  29   \n",
      "...           ...               ...                      ...  ..   \n",
      "1085       medium  sharedABMultiply  sharedABMultiply_kernel  70   \n",
      "1089       medium  sharedABMultiply  sharedABMultiply_kernel  71   \n",
      "1093       medium  sharedABMultiply  sharedABMultiply_kernel  72   \n",
      "1097       medium  sharedABMultiply  sharedABMultiply_kernel  73   \n",
      "1101       medium  sharedABMultiply  sharedABMultiply_kernel  74   \n",
      "1105       medium  sharedABMultiply  sharedABMultiply_kernel  75   \n",
      "1109       medium  sharedABMultiply  sharedABMultiply_kernel  76   \n",
      "1113       medium  sharedABMultiply  sharedABMultiply_kernel  77   \n",
      "1117       medium  sharedABMultiply  sharedABMultiply_kernel  78   \n",
      "1121       medium  sharedABMultiply  sharedABMultiply_kernel  79   \n",
      "1125       medium  sharedABMultiply  sharedABMultiply_kernel  80   \n",
      "1129       medium  sharedABMultiply  sharedABMultiply_kernel  81   \n",
      "1133       medium  sharedABMultiply  sharedABMultiply_kernel  82   \n",
      "1137       medium  sharedABMultiply  sharedABMultiply_kernel  83   \n",
      "1141       medium  sharedABMultiply  sharedABMultiply_kernel  84   \n",
      "1145       medium  sharedABMultiply  sharedABMultiply_kernel  85   \n",
      "1149       medium  sharedABMultiply  sharedABMultiply_kernel  86   \n",
      "1153       medium  sharedABMultiply  sharedABMultiply_kernel  87   \n",
      "1157       medium  sharedABMultiply  sharedABMultiply_kernel  88   \n",
      "1161       medium  sharedABMultiply  sharedABMultiply_kernel  89   \n",
      "1165       medium  sharedABMultiply  sharedABMultiply_kernel  90   \n",
      "1169       medium  sharedABMultiply  sharedABMultiply_kernel  91   \n",
      "1173       medium  sharedABMultiply  sharedABMultiply_kernel  92   \n",
      "1177       medium  sharedABMultiply  sharedABMultiply_kernel  93   \n",
      "1181       medium  sharedABMultiply  sharedABMultiply_kernel  94   \n",
      "1185       medium  sharedABMultiply  sharedABMultiply_kernel  95   \n",
      "1189       medium  sharedABMultiply  sharedABMultiply_kernel  96   \n",
      "1193       medium  sharedABMultiply  sharedABMultiply_kernel  97   \n",
      "1197       medium  sharedABMultiply  sharedABMultiply_kernel  98   \n",
      "1201       medium  sharedABMultiply  sharedABMultiply_kernel  99   \n",
      "\n",
      "              time  overhead  \n",
      "5     72399.361328         0  \n",
      "9     72398.248047         0  \n",
      "13    68380.984375         0  \n",
      "17    68519.853516         0  \n",
      "21    72237.582031         0  \n",
      "25    68344.060547         0  \n",
      "29    68497.281250         0  \n",
      "33    68485.623047         0  \n",
      "37    72455.656250         0  \n",
      "41    68424.181641         0  \n",
      "45    68523.085938         0  \n",
      "49    68454.501953         0  \n",
      "53    72356.667969         0  \n",
      "57    68956.085938         0  \n",
      "61    68238.927734         0  \n",
      "65    68449.511719         0  \n",
      "69    72611.628906         0  \n",
      "73    72161.894531         0  \n",
      "77    72204.453125         0  \n",
      "81    72626.972656         0  \n",
      "85    72016.660156         0  \n",
      "89    68477.324219         0  \n",
      "93    68706.392578         0  \n",
      "97    68928.845703         0  \n",
      "101   72659.052734         0  \n",
      "105   72620.203125         0  \n",
      "109   68401.785156         0  \n",
      "113   68577.810547         0  \n",
      "117   72013.810547         0  \n",
      "121   68406.966797         0  \n",
      "...            ...       ...  \n",
      "1085  14741.384766         0  \n",
      "1089  14586.457031         0  \n",
      "1093  14568.060547         0  \n",
      "1097  14574.896484         0  \n",
      "1101  14574.470703         0  \n",
      "1105  14584.564453         0  \n",
      "1109  14569.654297         0  \n",
      "1113  14578.781250         0  \n",
      "1117  14574.105469         0  \n",
      "1121  14561.609375         0  \n",
      "1125  14590.416016         0  \n",
      "1129  14575.242188         0  \n",
      "1133  14576.115234         0  \n",
      "1137  14576.011719         0  \n",
      "1141  14653.912109         0  \n",
      "1145  14573.101562         0  \n",
      "1149  14668.839844         0  \n",
      "1153  14584.921875         0  \n",
      "1157  14566.396484         6  \n",
      "1161  14584.544922         0  \n",
      "1165  14585.482422         0  \n",
      "1169  14585.824219         0  \n",
      "1173  14582.826172         0  \n",
      "1177  14572.306641         0  \n",
      "1181  14665.214844         0  \n",
      "1185  14575.285156         0  \n",
      "1189  14573.296875         0  \n",
      "1193  14585.906250         0  \n",
      "1197  14568.683594         0  \n",
      "1201  14712.166016         0  \n",
      "\n",
      "[300 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of 100 runtimes for each of the 3 kernels of memory striding for GPU optimisations are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i y -w 800 -h 300 -u px\n",
    "\n",
    "library(ggplot2)\n",
    "pp = ggplot(y, aes_string(x='time', colour = 'region')) + geom_histogram(binwidth=.5)\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Do these distributions appear suspect? Perhaps move the timing regions to outside of the loop and divide by iterations -- in the C host source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coalescedMultiply_kernel</th>\n",
       "      <td>13718.497070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharedABMultiply_kernel</th>\n",
       "      <td>14575.495117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simpleMultiply_kernel</th>\n",
       "      <td>68744.715821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time (ms)\n",
       "region                                \n",
       "coalescedMultiply_kernel  13718.497070\n",
       "sharedABMultiply_kernel   14575.495117\n",
       "simpleMultiply_kernel     68744.715821"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.drop(['id','overhead'],axis=1)\n",
    "z = z.rename(columns={'time':'time (ms)'})\n",
    "z.groupby([\"region\"]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AIWC feature-space per kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f sbd aiwc-tester lsb.*.r0* aiwc_*.csv aiwc_*_itb.log Rplots.pdf cpu-loop-block cpu-mandelbrot-vectorization\n",
      "g++ cpu-loop-blocking.cpp -o cpu-loop-block -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ cpu-mandelbrot-vectorization.cpp -o cpu-mandelbrot-vectorization -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ aiwc-tester.cpp -o aiwc-tester -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "***** LSB_Init >gpu_memory_access< writing to >lsb.gpu_memory_access.r0< *****\n",
      "Attempting kernel: ./gpu-strided-global-memory-access-unoptimised.cl with contents:\n",
      "//shared memory in matrix multiplication ported from the [cuda c best practices guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-aa)\n",
      "\n",
      "\n",
      "__kernel void simpleMultiply(__global float *a,__global float *b,__global float *c, int N)\n",
      "{\n",
      "    const int globalRow = get_global_id(0); // Row ID of C (0..M)\n",
      "    const int globalCol = get_global_id(1); // Col ID of C (0..N)\n",
      " \n",
      "    // Compute a single element (loop over K)\n",
      "    float acc = 0.0f;\n",
      "    for (int k=0; k<N; k++) {\n",
      "        acc += b[k*N + globalCol] * a[globalRow*N + k];\n",
      "    }\n",
      " \n",
      "    // Store the result\n",
      "    c[globalRow*N + globalCol] = acc;\n",
      "}\n",
      "\n",
      "__kernel void coalescedMultiply(const __global float* A, \n",
      "                                const __global float* B,\n",
      "                                __global float* C, const int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = get_global_id(0);\n",
      "    const int globalCol = get_global_id(1);\n",
      "    //int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y; //get_global_id()\n",
      "    //int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x; //get_global_id()\n",
      "    __private float sum = 0.0f;\n",
      "\n",
      "    const int numTiles = N / TILE_DIM;\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        aTile[localRow][localCol] = A[tiledRow];\n",
      "        //aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        for (int k = 0; k < TILE_DIM; k++) {\n",
      "            sum += aTile[localRow][k] * B[(i*TILE_DIM+k)*N+globalCol];\n",
      "        }\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        \n",
      "    }\n",
      "    C[globalRow*N+globalCol] = sum;\n",
      "}\n",
      "\n",
      "__kernel void sharedABMultiply(__global float *A, __global float* B, __global float *C, int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM],\n",
      "                  bTile[TILE_DIM][TILE_DIM];\n",
      "    \n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = get_global_id(0);\n",
      "    const int globalCol = get_global_id(1);\n",
      "    \n",
      "    float sum = 0.0f;\n",
      "    const int numTiles = N / TILE_DIM;\n",
      "\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "    //    aTile[localRow][localCol] = A[row*TILE_DIM+get_local_id(0)];\n",
      "    //    bTile[localRow][localCol] = B[get_local_id(1)*N+col];\n",
      "    //    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\n",
      "        aTile[localRow][localCol] = A[tiledRow];\n",
      "        bTile[localCol][localRow] = B[tiledCol];\n",
      "\n",
      "        // aTile[localRow][localCol] = A[globalRow*N+localCol+i*TILE_DIM];\n",
      "        // bTile[localRow][localCol] = B[localRow + TILE_DIM*get_group_id(1) \n",
      "        //                             + N*(TILE_DIM*get_group_id(0) + localCol)]; // Implicit transpose\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);                \n",
      "        for (int k = 0; k < TILE_DIM; k++) {\n",
      "            sum += aTile[localRow][k]* bTile[localCol][k]; //???\n",
      "        }\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      "\n",
      "    C[globalRow*N+globalCol] = sum;\n",
      "}\n",
      "\n",
      "/*\n",
      "OpenCL Kernels for matrix multiplicatioglobalRow*N+i*TILE_DIM + localColby Cedric Nugeteren\n",
      "\n",
      "    The MIT License (MIT)\n",
      "\n",
      "Copyright (c) 2014 SURFsara\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in\n",
      "all copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
      "THE SOFTWARE.\n",
      "*/\n",
      "\n",
      "/*\n",
      "    Coalesced and tiled calculations -- splitting the M*N matrix\n",
      "    into several k*k workgroups and calculating smartly after\n",
      "    coalescing into shared memory\n",
      "*/\n",
      "//__kernel void GEMM2(__global float *a,__global float *b,__global float *c, int N)\n",
      "// __kernel void GEMM2(  const __global float* A,\n",
      "//                       const __global float* B,\n",
      "//                       __global float* C,\n",
      "//                       const int N) {\n",
      "    \n",
      "//     // Thread identifiers\n",
      "//     const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "//     const int col = get_local_id(1); // Local col ID (max: TS)\n",
      "//     const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "//     const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "//     // Local memory to fit a tile of TS*TS elements of A and B\n",
      "//     __local float Asub[TILE_DIM][TILE_DIM];\n",
      "//     __local float Bsub[TILE_DIM][TILE_DIM];\n",
      " \n",
      "//     // Initialise the accumulation register\n",
      "//     float acc = 0.0f;\n",
      "    \n",
      "//     // Loop over all tiles\n",
      "//     const int numTiles = N/TILE_DIM;\n",
      "//     for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "//         // Load one tile of A and B into local memory\n",
      "//         const int tiledRow = TILE_DIM*t + row;\n",
      "//         const int tiledCol = TILE_DIM*t + col;\n",
      "//         //Asub[col][row] = A[globalCol*N + tiledRow];\n",
      "//         //Bsub[col][row] = B[tiledCol*N + globalRow];\n",
      "\n",
      "//         Asub[col][row] = A[tiledCol*N + globalRow];\n",
      "//         Bsub[col][row] = B[globalCol*N + tiledRow];\n",
      " \n",
      "//         // Synchronise to make sure the tile is loaded\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "//         // Perform the computation for a single tile\n",
      "//         for (int k=0; k<TILE_DIM; k++) {\n",
      "//             //acc += Asub[col][k] * Bsub[k][row];\n",
      "//             acc += Asub[k][row] * Bsub[col][k];\n",
      "\n",
      "//         }\n",
      " \n",
      "//         // Synchronise before loading the next tile\n",
      "//         barrier(CLK_LOCAL_MEM_FENCE);\n",
      "//     }\n",
      "//     // Store the final result in C32\n",
      "//     //C[globalCol + globalRow*N] = acc;32\n",
      "//     C[globalCol*N + globalRow] = acc;\n",
      "// }\n",
      "\n",
      "__kernel void GEMM2Multiply(const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C,\n",
      "                      const int N) {\n",
      "\n",
      "\n",
      "    const int localRow = get_local_id(0);\n",
      "    const int localCol = get_local_id(1);\n",
      "\n",
      "    const int globalRow = localRow + get_group_id(0) * get_local_size(0);\n",
      "    const int globalCol = localCol + get_group_id(1) * get_local_size(1);\n",
      "\n",
      "    __local float ASub[TILE_DIM][TILE_DIM];\n",
      "    __local float BSub[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    float acc = 0.0f;\n",
      "\n",
      "    const int numTiles = N/TILE_DIM;\n",
      "    for (int i = 0; i < numTiles; i++) {\n",
      "        const int tiledRow = globalRow*N+i*TILE_DIM + localCol;\n",
      "        const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;\n",
      "        ASub[localRow][localCol] = A[tiledRow];\n",
      "        BSub[localRow][localCol] = B[tiledCol];\n",
      "\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    \n",
      "        for (int k=0; k<TILE_DIM; k++) {\n",
      "            //acc += Asub[col][k] * Bsub[k][row];\n",
      "            acc += ASub[localRow][k] * BSub[k][localCol];\n",
      "        }\n",
      "\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      "    C[globalRow*N + globalCol] = acc;\n",
      "}\n",
      "\n",
      "/*\n",
      "__kernel void GEMM2(const int M, const int N, const int K,\n",
      "                      const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C) {\n",
      "    \n",
      "    // Thread identifiers\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS)\n",
      "    const int globalRow = TS*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "    const int globalCol = TS*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\n",
      "    __local float Asub[TS][TS];\n",
      "    __local float Bsub[TS][TS];\n",
      " \n",
      "    // Initialise the accumulation register\n",
      "    float acc = 0.0f;\n",
      "    \n",
      "    // Loop over all tiles\n",
      "    const int numTiles = K/TS;\n",
      "    for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "        // Load one tile of A and B into local memory\n",
      "        const int tiledRow = TS*t + row;\n",
      "        const int tiledCol = TS*t + col;\n",
      "        Asub[col][row] = A[tiledCol*M + globalRow];\n",
      "        Bsub[col][row] = B[globalCol*K + tiledRow];\n",
      " \n",
      "        // Synchronise to make sure the tile is loaded\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "        // Perform the computation for a single tile\n",
      "        for (int k=0; k<TS; k++) {\n",
      "            acc += Asub[k][row] * Bsub[col][k];\n",
      "        }\n",
      " \n",
      "        // Synchronise before loading the next tile\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      " \n",
      "    // Store the final result in C\n",
      "    C[glo\n",
      "*/\n",
      "\n",
      "\n",
      "/*\n",
      "    More work per thread: by factor WPT.\n",
      "*/\n",
      "/*\n",
      "__kernel void myGEMM3(const __global float* A,\n",
      "                      const __global float* B,\n",
      "                      __global float* C, const int N) {\n",
      "    \n",
      "    // Thread identifiers\n",
      "    const int row = get_local_id(0); // Local row ID (max: TS)\n",
      "    const int col = get_local_id(1); // Local col ID (max: TS/WPT == RTS)\n",
      "    const int globalRow = TILE_DIM*get_group_id(0) + row; // Row ID of C (0..M)\n",
      "    const int globalCol = TILE_DIM*get_group_id(1) + col; // Col ID of C (0..N)\n",
      " \n",
      "    // Local memory to fit a tile of TS*TS elements of A and B\n",
      "    __local float Asub[TILE_DIM][TILE_DIM];\n",
      "    __local float Bsub[TILE_DIM][TILE_DIM];\n",
      " \n",
      "    // Initialise the accumulation registers\n",
      "    float acc[WPT];\n",
      "    for (int w=0; w<WPT; w++) {\n",
      "        acc[w] = 0.0f;\n",
      "    }\n",
      "    \n",
      "    // Loop over all tiles\n",
      "    const int numTiles = N/TILE_DIM;\n",
      "    for (int t=0; t<numTiles; t++) {\n",
      " \n",
      "        // Load one tile of A and B into local memory\n",
      "        for (int w=0; w<WPT; w++) {\n",
      "            const int tiledRow = TILE_DIM*t + row;\n",
      "            const int tiledCol = T*t + col;\n",
      "            Asub[col + w*RTS][row] = A[(tiledCol + w*RTS)*M + globalRow];\n",
      "            Bsub[col + w*RTS][row] = B[(globalCol + w*RTS)*K + tiledRow];\n",
      "        }\n",
      "        \n",
      "        // Synchronise to make sure the tile is loaded\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      " \n",
      "        // Perform the computation for a single tile\n",
      "        for (int k=0; k<TS; k++) {\n",
      "            for (int w=0; w<WPT; w++) {\n",
      "                acc[w] += Asub[k][row] * Bsub[col + w*RTS][k];\n",
      "            }\n",
      "        }\n",
      " \n",
      "        // Synchronise before loading the next tile\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      " \n",
      "    // Store the final results in C\n",
      "    for (int w=0; w<WPT; w++) {\n",
      "        C[(globalCol + w*RTS)*M + globalRow] = acc[w];\n",
      "    }\n",
      "}\n",
      "*/\n",
      "\n",
      "/*\n",
      "Wider data access instructions\n",
      "*/\n",
      "M = 1408 N = 1408 total KiB = 23232\n",
      "Operating on a 1408x1408 matrix with a tile size 32...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminate called after throwing an instance of 'std::bad_alloc'\n",
      "  what():  std::bad_alloc\n",
      "Aborted (core dumped)\n"
     ]
    }
   ],
   "source": [
    "! make clean\n",
    "! make\n",
    "! $OCLGRIND/bin/oclgrind --workload-characterisation ./gpu-stride ./gpu-strided-global-memory-access-unoptimised.cl $PROBLEM_SIZE 0 0 aiwc\n",
    "! rm -f lsb.*.r0* #we aren't interested in runtime data anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse AIWC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'aiwc_simpleMultiply_0.csv' does not exist: b'aiwc_simpleMultiply_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0e6c3cb7fec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimpleMultiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aiwc_simpleMultiply_0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcoalescedMultiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aiwc_coalescedMultiply_0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msharedABMultiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aiwc_sharedABMultiply_0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGEMM2Multiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aiwc_GEMM2Multiply_0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'aiwc_simpleMultiply_0.csv' does not exist: b'aiwc_simpleMultiply_0.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "simpleMultiply = pd.read_csv('aiwc_simpleMultiply_0.csv', sep=\",\")\n",
    "coalescedMultiply = pd.read_csv('aiwc_coalescedMultiply_0.csv', sep=\",\")\n",
    "sharedABMultiply = pd.read_csv('aiwc_sharedABMultiply_0.csv', sep=\",\")\n",
    "GEMM2Multiply = pd.read_csv('aiwc_GEMM2Multiply_0.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise according to existing data -- from the predictive modelling paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i simpleMultiply -i coalescedMultiply -i sharedABMultiply -i GEMM2Multiply -o featdata.all\n",
    "\n",
    "simpleMultiply$application <- \"matrix_multiplication\"\n",
    "simpleMultiply$kernel <- \"simple_multiply\"\n",
    "simpleMultiply$invocation <- 0\n",
    "simpleMultiply$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "coalescedMultiply$application <- \"matrix_multiplication\"\n",
    "coalescedMultiply$kernel <- \"coalesced_multiply\"\n",
    "coalescedMultiply$invocation <- 0\n",
    "coalescedMultiply$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "sharedABMultiply$application <- \"matrix_multiplication\"\n",
    "sharedABMultiply$kernel <- \"shared_ab_multiply\"\n",
    "sharedABMultiply$invocation <- 0\n",
    "sharedABMultiply$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "GEMM2Multiply$application <- \"matrix_multiplication\"\n",
    "GEMM2Multiply$kernel <- \"GEMM2Multiply\"\n",
    "GEMM2Multiply$invocation <- 0\n",
    "GEMM2Multiply$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "featdata.all <- rbind(simpleMultiply,coalescedMultiply)\n",
    "featdata.all <- rbind(featdata.all,sharedABMultiply)\n",
    "featdata.all <- rbind(featdata.all,GEMM2Multiply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studentise the AIWC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i featdata.all -o aiwc\n",
    "\n",
    "source('/opencl-predictions-with-aiwc/codes/restructure_aiwc_data.R')\n",
    "aiwc <- reorder_features(featdata.all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between AIWC feature-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i aiwc -w 800 -h 800 -u px\n",
    "\n",
    "options(jupyter.plot_mimetypes = 'image/png')\n",
    "\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "aiwc.of.interest <- subset(aiwc, application == \"matrix_multiplication\")\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -size)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -invocation)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -application)\n",
    "\n",
    "melted = melt(aiwc.of.interest, id.var = 'kernel')\n",
    "#pdf(\"test.pdf\")\n",
    "ggplot(melted, aes(x = variable, y = value, fill = kernel)) + geom_bar(stat = \"identity\", position = 'dodge') +\n",
    "    scale_x_discrete(name = \"AIWC feature\") + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n",
    "#dev.off()\n",
    "\n",
    "#ggsave(sprintf(\"time_matrixMultiply_%s.png\", \"large\"))#, plot = last_plot(), device = NULL, path = NULL,\n",
    "  #scale = 1, width = NA, height = NA,\n",
    "  #dpi = 300, limitsize = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"time_matrixMultiply_large.png\" width=\"2000\" alt=\"Figure . Matrix Multiply Features\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Accuracy Of AIWC Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o model\n",
    "\n",
    "library(ranger)\n",
    "\n",
    "load(\"/opencl-predictions-with-aiwc/data/intermediate/full_dat.Rda\")\n",
    "\n",
    "#manually typecast integer variables\n",
    "int.inds <- c(2,6,7,8,9,10,11,12,13,16,17,29,30,34,37)\n",
    "\n",
    "#standardise numeric variables\n",
    "num.inds <- lapply(full_dat, is.numeric)\n",
    "num.inds <- as.logical(num.inds)\n",
    "\n",
    "for (i in seq(along = num.inds)){\n",
    "            feature.name = names(full_dat[i])\n",
    "            ifelse((any(i == int.inds) || num.inds[i] == 'FALSE' || feature.name == \"kernel_time\"), next, full_dat[i] <- scale(full_dat[i]))\n",
    "                                } #end i loop\n",
    "\n",
    "#use 20% of data for training\n",
    "#sampled_indices <- sample(seq_len(nrow(full_dat)), size = round(nrow(full_dat)*0.2))\n",
    "#train_dat <- full_dat[sampled_indices, ]\n",
    "#test_dat <- full_dat[-sampled_indices, ]\n",
    "#or...\n",
    "#use 100% of data for training\n",
    "train_dat <- full_dat\n",
    "\n",
    "#remove certain variables unavailable during real-world training\n",
    "train_dat = subset(train_dat, select = -size)\n",
    "train_dat = subset(train_dat, select = -application)\n",
    "train_dat = subset(train_dat, select = -kernel)\n",
    "train_dat = subset(train_dat, select = -total_time)\n",
    "\n",
    "#build the model\n",
    "rgd.aiwc <- ranger(log(kernel_time)~.,\n",
    "                   data = train_dat,\n",
    "                   num.trees = 505,\n",
    "                   mtry = 30,\n",
    "                   min.node.size = 9,\n",
    "                   importance = \"impurity\",\n",
    "                   splitrule = 'variance',\n",
    "                   respect.unordered.factors = 'order')\n",
    "\n",
    "model <- rgd.aiwc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction with our AIWC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"simple multiply 96.7 (ms)\"\n",
      "[1] \"coalesced multiply 95.71 (ms)\"\n",
      "[1] \"shared ab multiply 98.37 (ms)\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i aiwc -i model -o predicted\n",
    "\n",
    "#manually typecast integer variables\n",
    "#int.inds <- c(2,6,7,8,9,10,11,12,13,16,17,29,30,34,37)\n",
    "\n",
    "#standardise numeric variables\n",
    "#num.inds <- lapply(aiwc, is.numeric)\n",
    "#num.inds <- as.logical(num.inds)\n",
    "\n",
    "#for (i in seq(along = num.inds)){\n",
    "#            feature.name = names(aiwc[i])\n",
    "#            ifelse((any(i == int.inds) || num.inds[i] == 'FALSE' || feature.name == \"kernel_time\"), next, aiwc[i] <- scale(aiwc[i]))\n",
    "#                                } #end i loop\n",
    "predicted <- data.frame()\n",
    "\n",
    "x <- subset(aiwc, kernel==\"simple_multiply\")\n",
    "x$device = 'gtx1080'\n",
    "x$run = 0\n",
    "prediction <- predict(model,type='response',data=x)\n",
    "print(paste(\"simple multiply\", round(exp(prediction$pred),digits=2), \"(ms)\"))\n",
    "predicted <- rbind(predicted, data.frame('region'='simple_multiply','predicted time (ms)'=round(exp(prediction$pred),digits=2)))\n",
    "\n",
    "x <- subset(aiwc, kernel==\"coalesced_multiply\")\n",
    "x$device = 'gtx1080'\n",
    "x$run = 0\n",
    "prediction <- predict(model,type='response',data=x)\n",
    "print(paste(\"coalesced multiply\", round(exp(prediction$pred),digits=2), \"(ms)\"))\n",
    "predicted <- rbind(predicted, data.frame('region'='coalesced_multiply','predicted time (ms)'=round(exp(prediction$pred),digits=2)))\n",
    "\n",
    "x <- subset(aiwc, kernel==\"shared_ab_multiply\")\n",
    "x$device = 'gtx1080'\n",
    "x$run = 0\n",
    "prediction <- predict(model,type='response',data=x)\n",
    "print(paste(\"shared ab multiply\", round(exp(prediction$pred),digits=2), \"(ms)\"))\n",
    "predicted <- rbind(predicted, data.frame('region'='shared_ab_multiply','predicted time (ms)'=round(exp(prediction$pred),digits=2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predictions against measured times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>predicted.time..ms.</th>\n",
       "      <th>time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_multiply</td>\n",
       "      <td>90.98</td>\n",
       "      <td>540.314893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coalesced_multiply</td>\n",
       "      <td>1289.74</td>\n",
       "      <td>290.453984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shared_ab_multiply</td>\n",
       "      <td>3941.15</td>\n",
       "      <td>167.844932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region  predicted.time..ms.   time (ms)\n",
       "0     simple_multiply                90.98  540.314893\n",
       "1  coalesced_multiply              1289.74  290.453984\n",
       "2  shared_ab_multiply              3941.15  167.844932"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth = z\n",
    "groundtruth = groundtruth.groupby(['region']).mean()\n",
    "\n",
    "groundtruth = groundtruth.rename({'simpleMultiply_kernel':'simple_multiply',\n",
    "                                  'coalescedMultiply_kernel':'coalesced_multiply',\n",
    "                                  'sharedABMultiply_kernel':'shared_ab_multiply'})\n",
    "comparison = pd.merge(predicted,groundtruth,left_on='region',right_on='region')\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The predictive accuracy is bad for both the simple and coalesced case -- reasons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Blocking Example 4-25 from Intel 64 and IA-32 Architectures Optimization Reference Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate runtime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment and collect runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f sbd aiwc-tester lsb.*.r0* aiwc_*.csv aiwc_*_itb.log Rplots.pdf cpu-loop-block cpu-mandelbrot-vectorization\n",
      "g++ cpu-loop-blocking.cpp -o cpu-loop-block -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ cpu-mandelbrot-vectorization.cpp -o cpu-mandelbrot-vectorization -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "g++ aiwc-tester.cpp -o aiwc-tester -lOpenCL -llsb -L/libscibench/lib -I/libscibench/include -std=c++11\n",
      "***** LSB_Init >cpu_loop_blocking< writing to >lsb.cpu_loop_blocking.r0< *****\n",
      "Attempting kernel: ./cpu-loop-blocking.cl with contents:\n",
      "//Loop Blocking Example 4-25 from https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf in Section 4.5.3 Loop Blocking\n",
      "//TODO: verify loop-blocking correctness\n",
      "__kernel void original_loop(__global float* A, __global float* B)\n",
      "{\n",
      "    //get_group_id(0) * get_local_size(0) + get_local_id(0);//not needed -- intel tests only for single thread\n",
      "    for (int i=0; i< MAX; i++) {\n",
      "        for (int j=0; j< MAX; j++) {\n",
      "            //A[i,j] = A[i,j] + B[j, i];\n",
      "            A[i*MAX+j] = A[i*MAX+j] + B[j*MAX+i];\n",
      "        } \n",
      "    }\n",
      "}\n",
      "\n",
      "__kernel void transformed_loop_after_blocking(__global float* A, __global float* B)\n",
      "{\n",
      "    int i,j,ii,jj;\n",
      "    for (i=0; i< MAX; i+=BLOCK_SIZE) {\n",
      "        for (j=0; j< MAX; j+=BLOCK_SIZE) {\n",
      "            for (ii=i; ii<i+BLOCK_SIZE; ii++) {\n",
      "                for (jj=j; jj<j+BLOCK_SIZE; jj++) {\n",
      "                    //A[ii,jj] = A[ii,jj] + B[jj, ii];\n",
      "                    A[ii*MAX+jj] = A[ii*MAX+jj] + B[jj*MAX+ii];\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "terminate called after throwing an instance of 'std::runtime_error'\n",
      "  what():  can't create context\n",
      "Aborted (core dumped)\n"
     ]
    }
   ],
   "source": [
    "! make clean; make\n",
    "! ./cpu-loop-block ./cpu-loop-blocking.cl $PROBLEM_SIZE 1 0 runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a36e3d56adc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lsb.cpu_loop_blocking.r0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'original_loop_kernel'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'transformed_loop_after_blocking_kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv('lsb.cpu_loop_blocking.r0', comment='#', sep=\"\\s+\")\n",
    "\n",
    "y = x[(x.region == 'original_loop_kernel') | (x.region == 'transformed_loop_after_blocking_kernel')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of 100 runtimes for each of the 2 kernels is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i y -w 800 -h 300 -u px\n",
    "\n",
    "library(ggplot2)\n",
    "pp = ggplot(y, aes_string(x='time', colour = 'region')) + geom_histogram(binwidth=.1)\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = y.drop(['id','overhead'],axis=1)\n",
    "z = z.rename(columns={'time':'time (mins)'})\n",
    "z.groupby([\"region\"]).median()*1.66667e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AIWC feature-space per kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! make clean\n",
    "! make\n",
    "! $OCLGRIND/bin/oclgrind --workload-characterisation ./cpu-loop-block ./cpu-loop-blocking.cl $PROBLEM_SIZE 0 0 aiwc\n",
    "! rm -f lsb.*.r0* #we aren't interested in runtime data anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse AIWC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "originalLoop = pd.read_csv('./aiwc_original_loop_0.csv', sep=\",\")\n",
    "transformedLoop = pd.read_csv('aiwc_transformed_loop_after_blocking_0.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise according to existing data -- from the predictive modelling paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i originalLoop -i transformedLoop -o featdata.all\n",
    "\n",
    "load('/opencl-predictions-with-aiwc/data/intermediate/featdata.Rda')\n",
    "\n",
    "originalLoop$application <- \"loop_blocking\"\n",
    "originalLoop$kernel <- \"original_loop\"\n",
    "originalLoop$invocation <- 0\n",
    "originalLoop$size <- \"tiny\"\n",
    "\n",
    "transformedLoop$application <- \"loop_blocking\"\n",
    "transformedLoop$kernel <- \"transformed_loop\"\n",
    "transformedLoop$invocation <- 0\n",
    "transformedLoop$size <- \"tiny\"\n",
    "\n",
    "featdata.all <- rbind(featdata.all,originalLoop)\n",
    "featdata.all <- rbind(featdata.all,transformedLoop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studentise the AIWC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i featdata.all -o aiwc\n",
    "\n",
    "source('/opencl-predictions-with-aiwc/codes/restructure_aiwc_data.R')\n",
    "pca_dat <- reorder_features(featdata.all)\n",
    "pca_dat$opcode <- scale(pca_dat$opcode,scale=TRUE)[,1]\n",
    "pca_dat$granularity <- scale(pca_dat$granularity,scale=TRUE)[,1]\n",
    "pca_dat$barriers_per_instruction <- scale(pca_dat$barriers_per_instruction,scale=TRUE)[,1]\n",
    "pca_dat$instructions_per_operand <- scale(pca_dat$instructions_per_operand,scale=TRUE)[,1]\n",
    "pca_dat$total_instruction_count <- scale(pca_dat$total_instruction_count,scale=TRUE)[,1]\n",
    "pca_dat$workitems <- scale(pca_dat$workitems,scale=TRUE)[,1]\n",
    "pca_dat$operand_sum <- scale(pca_dat$operand_sum,scale=TRUE)[,1]\n",
    "pca_dat$total_barriers_hit <- scale(pca_dat$total_barriers_hit,scale=TRUE)[,1]\n",
    "pca_dat$min_instructions_to_barrier <- scale(pca_dat$min_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$max_instructions_to_barrier <- scale(pca_dat$max_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$median_instructions_to_barrier <- scale(pca_dat$median_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$max_simd_width <- scale(pca_dat$max_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$mean_simd_width <- scale(pca_dat$mean_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$stddev_simd_width <- scale(pca_dat$stddev_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$total_memory_footprint <- scale(pca_dat$total_memory_footprint,scale=TRUE)[,1]\n",
    "pca_dat$ninety_percent_memory_footprint <- scale(pca_dat$ninety_percent_memory_footprint,scale=TRUE)[,1]\n",
    "pca_dat$global_memory_address_entropy <- scale(pca_dat$global_memory_address_entropy,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_1 <- scale(pca_dat$local_memory_address_entropy_1,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_2 <- scale(pca_dat$local_memory_address_entropy_2,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_3 <- scale(pca_dat$local_memory_address_entropy_3,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_4 <- scale(pca_dat$local_memory_address_entropy_4,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_5 <- scale(pca_dat$local_memory_address_entropy_5,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_6 <- scale(pca_dat$local_memory_address_entropy_6,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_7 <- scale(pca_dat$local_memory_address_entropy_7,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_8 <- scale(pca_dat$local_memory_address_entropy_8,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_9 <- scale(pca_dat$local_memory_address_entropy_9,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_10 <- scale(pca_dat$local_memory_address_entropy_10,scale=TRUE)[,1]\n",
    "pca_dat$total_unique_branch_instructions <- scale(pca_dat$total_unique_branch_instructions,scale=TRUE)[,1]\n",
    "pca_dat$ninety_percent_branch_instructions <- scale(pca_dat$ninety_percent_branch_instructions,scale=TRUE)[,1]\n",
    "pca_dat$branch_entropy_yokota <- scale(pca_dat$branch_entropy_yokota,scale=TRUE)[,1]\n",
    "pca_dat$branch_entropy_average_linear <- scale(pca_dat$branch_entropy_average_linear,scale=TRUE)[,1]\n",
    "aiwc <- pca_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between AIWC feature-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i aiwc -w 800 -h 800 -u px\n",
    "\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "aiwc.of.interest <- subset(aiwc, application == \"loop_blocking\")\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -size)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -invocation)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -application)\n",
    "\n",
    "melted = melt(aiwc.of.interest, id.var = 'kernel')\n",
    "ggplot(melted, aes(x = variable, y = value, fill = kernel)) + geom_bar(stat = \"identity\", position = 'dodge') +\n",
    "    scale_x_discrete(name = \"AIWC feature\") + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization of Mandelbrot Set -- Example 5-33 from Intel 64 and IA-32 Architectures Optimization Reference Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example examines the ability to improve the performance of CPU devices by using vectorisation / Single Instruction Multiple Data (SIMD) level optimization. This is done by first examining the code to produce a Mandelbrot set -- a sample is shown in Figure 1.\n",
    "\n",
    "<img src=\"mandelbrot.png\" width=\"200\" alt=\"Figure 1. Mandelbrot set\">\n",
    "\n",
    "<!--\n",
    "![Figure 1. Mandelbrot set](mandelbrot.png =250x)\n",
    "-->\n",
    "\n",
    "The optimization involves restucturing the code to pack four floating point values into the same register allowing 128 bits to be treated in the same instruction. The Intel codebook, from which this example was based, originally targeted SSEv4. However, since this is intel specific an OpenCL alternative was developed. Support for vectorization comes built into OpenCL using vector primatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate runtime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment and collect runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! make clean; make\n",
    "! ./cpu-mandelbrot-vectorization ./cpu-mandelbrot-vectorization-set-map.cl $PROBLEM_SIZE 1 0 runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv('lsb.cpu_vectorization.r0', comment='#', sep=\"\\s+\")\n",
    "\n",
    "y = x[(x.region == 'mandelbrot_kernel') | (x.region == 'mandelbrot_vectorized_kernel')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of 100 runtimes for each of the 2 kernels is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i y -w 800 -h 300 -u px\n",
    "\n",
    "library(ggplot2)\n",
    "pp = ggplot(y, aes_string(x='time', colour = 'region')) + geom_histogram(binwidth=.1)\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = y.drop(['id','overhead'],axis=1)\n",
    "z = z.rename(columns={'time':'time (ms)'})\n",
    "z.groupby([\"region\"]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AIWC feature-space per kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! make clean\n",
    "! make\n",
    "! $OCLGRIND/bin/oclgrind --workload-characterisation ./cpu-mandelbrot-vectorization ./cpu-mandelbrot-vectorization-set-map.cl $PROBLEM_SIZE 0 0 aiwc\n",
    "! rm -f lsb.*.r0* #we aren't interested in runtime data anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse AIWC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mandelbrot = pd.read_csv('./aiwc_mandelbrot_0.csv', sep=\",\")\n",
    "mandelbrotVectorized = pd.read_csv('./aiwc_mandelbrot_vectorized_0.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise according to existing data -- from the predictive modelling paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i mandelbrot -i mandelbrotVectorized -o featdata.all\n",
    "\n",
    "load('/opencl-predictions-with-aiwc/data/intermediate/featdata.Rda')\n",
    "\n",
    "mandelbrot$application <- \"mandelbrot_set\"\n",
    "mandelbrot$kernel <- \"mandelbrot\"\n",
    "mandelbrot$invocation <- 0\n",
    "mandelbrot$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "mandelbrotVectorized$application <- \"mandelbrot_set\"\n",
    "mandelbrotVectorized$kernel <- \"mandelbrot_vectorized\"\n",
    "mandelbrotVectorized$invocation <- 0\n",
    "mandelbrotVectorized$size <- Sys.getenv('PROBLEM_SIZE')\n",
    "\n",
    "featdata.all <- rbind(featdata.all,mandelbrot)\n",
    "featdata.all <- rbind(featdata.all,mandelbrotVectorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studentise the AIWC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i featdata.all -o aiwc\n",
    "\n",
    "source('/opencl-predictions-with-aiwc/codes/restructure_aiwc_data.R')\n",
    "pca_dat <- reorder_features(featdata.all)\n",
    "pca_dat$opcode <- scale(pca_dat$opcode,scale=TRUE)[,1]\n",
    "pca_dat$granularity <- scale(pca_dat$granularity,scale=TRUE)[,1]\n",
    "pca_dat$barriers_per_instruction <- scale(pca_dat$barriers_per_instruction,scale=TRUE)[,1]\n",
    "pca_dat$instructions_per_operand <- scale(pca_dat$instructions_per_operand,scale=TRUE)[,1]\n",
    "pca_dat$total_instruction_count <- scale(pca_dat$total_instruction_count,scale=TRUE)[,1]\n",
    "pca_dat$workitems <- scale(pca_dat$workitems,scale=TRUE)[,1]\n",
    "pca_dat$operand_sum <- scale(pca_dat$operand_sum,scale=TRUE)[,1]\n",
    "pca_dat$total_barriers_hit <- scale(pca_dat$total_barriers_hit,scale=TRUE)[,1]\n",
    "pca_dat$min_instructions_to_barrier <- scale(pca_dat$min_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$max_instructions_to_barrier <- scale(pca_dat$max_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$median_instructions_to_barrier <- scale(pca_dat$median_instructions_to_barrier,scale=TRUE)[,1]\n",
    "pca_dat$max_simd_width <- scale(pca_dat$max_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$mean_simd_width <- scale(pca_dat$mean_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$stddev_simd_width <- scale(pca_dat$stddev_simd_width,scale=TRUE)[,1]\n",
    "pca_dat$total_memory_footprint <- scale(pca_dat$total_memory_footprint,scale=TRUE)[,1]\n",
    "pca_dat$ninety_percent_memory_footprint <- scale(pca_dat$ninety_percent_memory_footprint,scale=TRUE)[,1]\n",
    "pca_dat$global_memory_address_entropy <- scale(pca_dat$global_memory_address_entropy,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_1 <- scale(pca_dat$local_memory_address_entropy_1,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_2 <- scale(pca_dat$local_memory_address_entropy_2,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_3 <- scale(pca_dat$local_memory_address_entropy_3,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_4 <- scale(pca_dat$local_memory_address_entropy_4,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_5 <- scale(pca_dat$local_memory_address_entropy_5,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_6 <- scale(pca_dat$local_memory_address_entropy_6,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_7 <- scale(pca_dat$local_memory_address_entropy_7,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_8 <- scale(pca_dat$local_memory_address_entropy_8,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_9 <- scale(pca_dat$local_memory_address_entropy_9,scale=TRUE)[,1]\n",
    "pca_dat$local_memory_address_entropy_10 <- scale(pca_dat$local_memory_address_entropy_10,scale=TRUE)[,1]\n",
    "pca_dat$total_unique_branch_instructions <- scale(pca_dat$total_unique_branch_instructions,scale=TRUE)[,1]\n",
    "pca_dat$ninety_percent_branch_instructions <- scale(pca_dat$ninety_percent_branch_instructions,scale=TRUE)[,1]\n",
    "pca_dat$branch_entropy_yokota <- scale(pca_dat$branch_entropy_yokota,scale=TRUE)[,1]\n",
    "pca_dat$branch_entropy_average_linear <- scale(pca_dat$branch_entropy_average_linear,scale=TRUE)[,1]\n",
    "aiwc <- pca_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between AIWC feature-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i aiwc -w 800 -h 800 -u px\n",
    "\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "aiwc.of.interest <- subset(aiwc, application == \"mandelbrot_set\")\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -size)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -invocation)\n",
    "aiwc.of.interest = subset(aiwc.of.interest, select = -application)\n",
    "\n",
    "melted = melt(aiwc.of.interest, id.var = 'kernel')\n",
    "ggplot(melted, aes(x = variable, y = value, fill = kernel)) + geom_bar(stat = \"identity\", position = 'dodge') +\n",
    "    scale_x_discrete(name = \"AIWC feature\") + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
