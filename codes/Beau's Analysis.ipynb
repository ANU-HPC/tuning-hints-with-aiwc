{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #CUDA C Best Practices Guide -- Shared Memory Optimisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the binary is up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\r\n"
     ]
    }
   ],
   "source": [
    "! make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment and collect the tiny runtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** LSB_Init >gpu_memory_access< writing to >lsb.gpu_memory_access.r0< *****\n",
      "Attempting kernel: ./gpu-strided-global-memory-access-unoptimised.cl with contents:\n",
      "//shared memory in matrix multiplication ported from the [cuda c best practices guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-aa)\n",
      "\n",
      "__kernel void simpleMultiply(__global float *a,__global float *b,__global float *c, int N)\n",
      "{\n",
      "    int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    float sum = 0.0f;\n",
      "    for (int i = 0; i < TILE_DIM; i++) {\n",
      "        sum += a[row*TILE_DIM+i] * b[i*N+col];\n",
      "    }\n",
      "    c[row*TILE_DIM+col] = sum;\n",
      "}\n",
      "\n",
      "__kernel void coalescedMultiply(__global float* a, __global float* b, __global float* c, int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM];\n",
      "    __local float bTile[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    float sum = 0.0f;\n",
      "\n",
      "    int x = get_local_id(0);\n",
      "    int y = get_local_id(1);\n",
      "\n",
      "    aTile[y][x] = a[row*TILE_DIM+x];\n",
      "    bTile[y][x] = b[y*N+col];\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    for (int i = 0; i < TILE_DIM; i++) {\n",
      "        sum += aTile[y][i]* bTile[i][x];\n",
      "    }\n",
      "    c[row*N+col] = sum;\n",
      "}\n",
      "\n",
      "\n",
      "__kernel void transposedCoalescedMultiply(__global float* a, __global float* b, __global float* c, int N)\n",
      "{\n",
      "    __local float aTile[TILE_DIM][TILE_DIM];\n",
      "    __local float transposedTile[TILE_DIM][TILE_DIM];\n",
      "\n",
      "    int row = get_group_id(1) * get_local_size(1) + get_local_id(1);//blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    int col = get_group_id(0) * get_local_size(0) + get_local_id(0);//blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    float sum = 0.0f;\n",
      "\n",
      "    int x = get_local_id(0);\n",
      "    int y = get_local_id(1);\n",
      "\n",
      "    aTile[y][x] = a[row*TILE_DIM+x];\n",
      "    transposedTile[x][y] = a[(get_group_id(0)*get_local_size(0) + get_local_id(1))*TILE_DIM + get_local_id(0)];\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "    for (int i = 0; i < TILE_DIM; i++) {\n",
      "        sum += aTile[y][i]*transposedTile[i][x];\n",
      "    }\n",
      "    c[row*N+col] = sum;\n",
      "}\n",
      "\n",
      "/*\n",
      "\n",
      "\n",
      "__global__ void coalescedMultiply(float *a, float *c, int M)\n",
      "{\n",
      "    __shared__ float aTile[TILE_DIM][TILE_DIM];\n",
      "    __shared__ float transposedTile[TILE_DIM][TILE_DIM+1];\n",
      "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    float sum = 0.0f;\n",
      "    aTile[threadIdx.y][threadIdx.x] = a[row*TILE_DIM+threadIdx.x];\n",
      "    transposedTile[threadIdx.x][threadIdx.y] =\n",
      "        a[(blockIdx.x*blockDim.x + threadIdx.y)*TILE_DIM +\n",
      "        threadIdx.x];  \n",
      "    __syncthreads();\n",
      "    for (int i = 0; i < TILE_DIM; i++) {\n",
      "        sum += aTile[threadIdx.y][i]* transposedTile[i][threadIdx.x];\n",
      "    }\n",
      "    c[row*M+col] = sum;\n",
      "}\n",
      "*/\n",
      "\n",
      "Operating on a 32x32 matrix with a tile size 32...\n",
      "******* LSB_Finalize *******\n"
     ]
    }
   ],
   "source": [
    "! ./sbd ./gpu-strided-global-memory-access-unoptimised.cl tiny 0 0 runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the runtimes (to ensure the OpenCL port of the cuda codes matches those shown in their paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a representation of the AIWC feature-space changing between kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
