\documentclass[review=false, sigchi]{acmart}

\usepackage{listings}
\usepackage{color}
\usepackage{pgfplots}
\usepackage{subfig}

\raggedbottom
\acmConference[IWOCL'20]{International Workshop on OpenCL}{April 27--29, 2020}{Munich, Germany}
%\editor{John B. Appleseed}
\title[Architecture-Independent Memory Access Pattern Analysis]{Characterising Optimizations to Memory Access Patterns using Architecture-Independent Program Features}

\author{Aditya Chilukuri}
\email{aditya.chilukuri@anu.edu.au}
\affiliation{%
	\institution{Australian National University}}

\author{Josh Milthorpe}
\email{josh.milthorpe@anu.edu.au}
\affiliation{%
	\institution{Australian National University}}

\author{Beau Johnston}
\email{beau.johnston@anu.edu.au}
\affiliation{%
	\institution{Australian National University}}

%\acmVolume{10} %TODO
%\acmNumber{10} %TODO
%\acmArticle{10} %TODO
\acmYear{2020}
\acmMonth{6}
\acmPrice{15.00}

\keywords{Architecture Independent Analysis, Heterogenous Computing, Workload Characterization, Memory Access Patterns} %TODO

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=C,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3,
	numbers=left
}

% tables (Josh) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{booktabs}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{array}
\renewcommand{\arraystretch}{1.2}  % stretch space between table rows a bit

\newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\definecolor{tableheadcolor}{rgb}{0.8,0.8,1.0}
\definecolor{tablealtcolor}{rgb}{0.9,0.9,0.95}

% bold table rows (use \rowstyle{\bffamily} on each bold row)
\newcolumntype{B}{>{\global\let\currentrowstyle\relax}}
\newcolumntype{^}{>{\currentrowstyle}}
\newcommand{\rowstyle}[1]{\gdef\currentrowstyle{#1}#1\ignorespaces}
\newcolumntype{C}{>{\bfseries}}

% sans-serif tables
\let\oldtabular\tabular
\let\endoldtabular\endtabular
\renewenvironment{tabular}{\sffamily\oldtabular}{\endoldtabular}

\begin{document}
	
	\begin{comment}
	proposed new abstract: 
	
	Context: AIWC gathers features of OpenCL programs which can be used to understand and predict program performance
	
	Problem: metrics aren't easily interpreted and don't reflect important memory access patterns that affect efficiency across all architectures
	
	Solution: new metrics
	
	Results: differences in metrics reflect optimizations for matrix multiply; improved performance prediction by x\% for Extended OpenDwarfs benchmarks
	
	Significance: as per last sentence\\
	\end{comment}

	\begin{abstract}
	
	%This paper addresses the challenge of profiling a code base to help programmers effectively optimize their codes for high performance.
	HPC developers are faced with the challenge of optimizing OpenCL workloads for high performance on novel architectures.
	The Architecture-Independent Workload Characterization (AIWC) tool is a plugin for the Oclgrind OpenCL simulator that gathers metrics of OpenCL programs used to understand and predict program performance on an arbitrary given hardware architecture.
	However, AIWC metrics are not always easily interpreted and do not reflect some important memory access patterns affecting efficiency across architectures.
	We propose the concept of parallel spatial locality: the locality of memory accesses by OpenCL work-items (threads) executing simultaneously.
	We implement the parallel spatial locality metric in the AIWC framework and analyse gathered results on matrix multiply and the Extended OpenDwarfs OpenCL benchmarks.
	The differences in the parallel spatial locality metric between implementations of matrix multiply reflect the optimizations performed.
	The new metric showcases the memory access patterns in the OpenDwarfs benchmarks that affect their performance on various architectures.
	%Current methods of analysing program behaviour have largely relied on performance counters on various architectures to provide architecture dependent metrics of code behaviour. 
	%However, if workload characteristics are tied to architectural features specific to a particular system, these analysis frameworks may not generalize to alternative or future systems.
	%Considering the trend towards heterogeneous computing, we work towards a framework to guide developers in optimizing codes for any given hardware target using the architecture independent workload characterization (AIWC) tool -- specifically in profiling memory access patterns of code. 
	%Metrics must be easily interpreted and conceptually linked to patterns in hardware-specific memory access optimizations.
	%To this end we propose, implement and analyse the addition of two new metrics to AIWC and present a new approach to profile spatial locality intrinsic to parallel codes.
	The improvements suggested to AIWC will help HPC developers better understand memory access patterns of complex codes, a crucial step in guiding optimization of codes for arbitrary hardware targets.
	\end{abstract}

	\maketitle	
	
	\section{Introduction}
	
	High-performance computing (HPC) systems are increasingly heterogeneous.
	A single node on a modern supercomputer may combine traditional CPUs with one or more accelerators such as GPUs, Field Programmable Gate Arrays (FPGAs), or many integrated core devices (MICs).
	High bandwidth interconnects support tight integration between multiple devices of different types on a single compute node.
	
	The OpenCL programming language is designed to support portability for heterogeneous systems by allowing a single code to execute on multiple hardware targets. 
	%It is possible for an engineer to write highly thread-divergent logical analysis code aimed at traditional CPUs; parallelisable data crunching kernels aimed at GPUs; and code to satisfy specialized computational requirements aimed at FPGAs -- all in a single code base using OpenCL. 
	The language provides support for individual \emph{kernels}, portions of parallelizable codes that make up a HPC code base, to be executed independently on diverse hardware targets such as traditional CPUs, GPUs and FPGAs \cite{khronosopenclworkinggroup2011opencl}. This gives HPC software developers greater flexibility by allowing codes aimed at a range of hardware targets to be written in a single programming language environment.
	
	Application codes differ in resource requirements, control structure and available parallelism. Similarly, compute devices differ in number and capabilities of execution units, processing model, and available resources.
	These heterogeneous computing environments present opportunities for software engineers and HPC integrators to design highly optimized systems with multiple kernels executing on hardware targets best suited for the diverse computational tasks performed by each kernel~\cite{spafford2010maestro}.
	However, this opportunity also presents a challenge in optimizing code to run on diverse architectures.
	The work reported here aims to help HPC developers understand and optimize memory access patterns to improve performance on heterogeneous systems.
	
	In the evolution of computer architectures over the last few decades, the exponential growth in computational capability has not been matched by proportional increases in memory speeds\cite{hennessycomparch}.
	Memory accesses pose larger bottlenecks to performance as application demand for main memory scales with the arithmetic capability of computer systems.
	To mitigate this latency, modern CPU designs have employed a wide range of cache technologies to reduce main memory accesses using the principle of \emph{spatial locality}: the observation that data that a program accesses close together in time tend to also be close together in memory.
	On the other hand, GPUs rely on hardware multithreading to hide memory latency, and their architectures favour ALU capability over sophisticated logic to manage a cache hierarchy and out-of-order execution. As a result, the performance of kernels on CPUs and GPUs alike is strongly dependent on memory access patterns intrinsic to the code. % We discuss the memory model design and the manufacturer recommended optimizations for NVIDIA GPUs in later sections..
	
	%We demonstrate the effectiveness of an architecture-independent analysis of codes in determining ... Our work guides optimization efforts for OpenCL codes running on increasingly diverse hardware by examining the current state of the art in architecture-independent metrics for memory access patterns. 
	
	
	%What we did briefly
	Our aim in this paper is to develop a framework to guide HPC software engineers in hardware-dependent code optimization -- specifically by guiding the improvement of memory access patterns.
	We provide examples of manufacturer-recommended code optimizations to improve memory access patterns on the target architecture, and examine these using the architecture-independent workload characterization (AIWC)~\cite{beauaiwc} plugin for Oclgrind.
	Our work highlights the benefits and challenges arising from an architecture-independent analysis of memory-based program characteristics.
	We propose two new metrics to AIWC to better characterize these memory-based optimizations.
	We measure the presented codes using the new metrics and demonstrate the metrics' effectiveness in capturing the essence of the optimizations performed.
	
	The structure of this paper is as follows.
	In section~\ref{motivating example} we use the example of matrix multiplication on a GPU to showcase the specific vendor-recommended optimizations our work aims to measure.
	In section~\ref{related work} we discuss how AIWC and its precursors profiled memory access patterns in an architecture-independent fashion, and relevant architecture dependent approaches to memory access profiling.
	In section \ref{method} we present a methodology to critically examine the architecture-independent workload characterization tool, which we use in section~\ref{results} to measure the accuracy of AIWC in profiling the impact of performance optimizations to various OpenCL codes.
	In section~\ref{discussion} we suggest new methods to accurately capture code patterns correlating to hardware-specific memory optimizations.
	Finally, in section~\ref{future work} we discuss further avenues to extend our work and conclude.
	
	\section{Motivating Example} \label{motivating example}
	
	We aim to capture the essence of vendor-recommended optimizations for target architectures in our metrics.
	We demonstrate the optimization strategies using an OpenCL kernel which multiplies square matrices of order $N$.
	We start with a simple unoptimized kernel, and then improve the memory access patterns of this kernel by incrementally performing the optimizations recommended in the CUDA Optimization Handbook \cite{cudaoptimisation} for NVIDIA GPUs.
	These incrementally optimized OpenCL codes are then analysed using AIWC to determine the accuracy in profiling favourable memory access patterns of the current framework and the proposed extensions to AIWC.
	
	\subsection{Simple Unoptimized Matrix Multiplication}
	
	The unoptimized matrix multiplication kernel presented in Appendix~\ref{simpleMultiply} is used as a baseline to validate the performance improvements measured from each following optimization.
	Each thread of the kernel updates the $(globalRow, globalCol)$ element of matrix $C$ by computing the dot product of the corresponding row of $A$ and column of $B$.
	
	\subsection{Using Shared Memory to Coalesce Global Memory Access to Matrix A} 
	
	We first notice that the number of global memory accesses to matrices A and B increases as $O(N^3)$ with respect to matrix size $N$.
	Global memory is typically located off-chip and accesses induce large delays.
	NVIDIA GPUs coalesce global memory loads and stores issued within thread-groups into as few DRAM transactions as possible.
	Multiple global memory loads and stores are coalesced into a single transaction when certain device-specific conditions are met. 
	On most NVIDIA GPUs, data accesses are coalesced when multiple requests are made for memory locations from the same cache line in global memory \cite{cudamanual}. Appendix \ref{coalescedAMultiply} contains the \texttt{coalescedAMultiply} kernel, which coalesces accesses to matrix $A$ by storing \emph{tiles}, or square blocks, of $A$'s values into shared memory. 
	
	% 9.2.1.2: Misaligned access pattern
	
	\subsection{Using Shared Memory to store Tiles of Matrix B} 
	
	The code is further optimized by improving how the previous \texttt{coalescedAMultiply} kernel reads from Matrix $B$.
	While each thread in coalescedAMultiply reads only a single element of matrix $A$ from global memory, each thread reads a full column of matrix $B$.
	The repeated reads of elements of matrix $B$ across multiple threads can be alleviated by reading tiles from matrix $B$ into shared memory.
	Appendix~\ref{coalescedABMultiply} contains the \texttt{coalescedAB} kernel which performs this optimization.
	
	\subsection{Optimising handling of shared memory} 
	
	NVIDIA shared memory is divided into multiple banks -- stored in independent memory modules -- to allow parallel accesses to shared memory. Bank conflicts occur when shared memory in the same bank is accessed concurrently. The code in \texttt{coalescedAB} kernel is further optimized by implicitly transposing tiles of Matrix $A$ while loading from global memory. This improves memory bank utilization during reads to shared memory tiles are performed during the necessary computation. The \texttt{coalescedABT} kernel demonstrates this optimization by modifying lines 20,21 of \texttt{coalescedAB} to:
	
	\begin{lstlisting}[firstnumber=20]
		ASub[localCol][localRow] = A[tiledRow];
		BSub[localRow][localCol] = B[tiledCol];
	\end{lstlisting}
	
	
	\subsection{Alignment of Memory Allocation}
	
	Memory access alignment is important to best utilize all parts of GPU memory architecture. Global memory buffer alignment can allow threads to access blocks of global memory aligned to the nearest cache line. This enables coalescing of memory accesses. If buffers are misaligned, parallel memory requests may cross over cache lines, and may double the number of slow global memory accesses needed as demonstrated in figures \ref{fig: Simple memory alignment} and \ref{fig: Simple memory misalignment}.
	
	\begin{figure}[h]
		\includegraphics[width=\linewidth]{aligned_access_coalescing.pdf}
		\caption{All threads access memory aligned to nearest cache line in parallel \cite{cudaoptimisation}}
		\label{fig: Simple memory alignment}
	\end{figure}
	
	\begin{figure}[h]
		\includegraphics[width=\linewidth]{misaligned_access_coalescing.pdf}
		\caption{Unaligned sequential memory addresses fit in two cache lines \cite{cudaoptimisation}}
		\label{fig: Simple memory misalignment}
	\end{figure}
	
	A similar principle applies when using shared memory. Bank conflicts may be reduced by aligning allocations of shared memory buffers. The \texttt{alignedABT} kernel improves the alignment of shared memory tiles in \texttt{coalescedABT}.
	An arbitrary large alignment value of 4096 is chosen as it is larger than the cache line size of modern hardware and attributed to the local array declarations in the existing code as shown below.
	
	\begin{lstlisting}
		__local float aTile[TILE_DIM][TILE_DIM] __attribute__ ((aligned(4096)));
		__local float bTile[TILE_DIM][TILE_DIM] __attribute__ ((aligned(4096)));
	\end{lstlisting}
	
	All the examples above are an incomplete listing of optimization strategies developers can apply to code targeted at NVIDIA GPUs.
	In section~\ref{results}, we will compare the collected AIWC metrics with the expected effect of each optimization, to examine how effectively our methodology uncovers underlying bottlenecks and guides optimization efforts.
	
	\flushbottom
	\section{Related Work} \label{related work}
	
	Hoste and Eeckout \cite{hoste2007microarchitecture} show that while conventional architecture dependent characteristics are useful in locating performance bottlenecks, they can hide the underlying, inherent program behaviour causing performance bottlenecks. A conceptual understanding of the performance characteristics of complex codes is necessary for the programmer to effectively optimize these codes. Architecture dependent characteristics typically include instructions per cycle (IPC), cache and branch prediction miss rates, page faults and DRAM bus data transfer rates. These are typically collected using hardware performance counters available on most target architectures. These performance counters do not serve to guide optimization beyond highlighting potential bottlenecks \cite{hoste2007microarchitecture, ganesan2008performance}. Further, in many cases, architecture dependent characteristics usually cannot be directly correlated to specific code patterns. For example, the causes of high cache miss rates in the execution of a program are too complex and widely variant on microarchitecture specific features such as cache size, prefetch behaviour and cache placement policies. In summary, we argue that a HPC developer tasked with optimizing code for a given hardware target would benefit from architecture-independent metrics of the code that can be conceptually correlated to hardware specific optimization patterns. Such architecture-independent metrics will effectively guide the HPC developer's workflow in both finding and fixing bottlenecks in code performance.
	
	The Architecture-Independent Workload Characterization (AIWC) tool \cite{beauaiwc} relies on a set of instruction set architecture (ISA)-independent features determined by Shao and Brooks \cite{shao2013isa}. AIWC measures memory based metrics to characterize the target code's memory behaviours. AIWC firstly collects aggregate simple counts such as the (i) total memory footprint, the total number of unique addresses accessed; and (ii) 90\% memory footprint, the number of unique addresses covering 90\% of memory accesses. A small ratio of 90\% memory footprint to total memory footprint correlates to programs accessing the same small subset of memory addresses repeatedly -- which can be linked to increased performance in a cached memory hierarchy.
	
	AIWC also records the global memory address entropy (GMAE), a positive real number corresponding to the randomness of the memory access distribution of a program. To measure locality of memory accesses, AIWC collects the local memory address entropy (LMAE) of memory addresses accessed after dropping $n$ least significant bits of all memory addresses accessed by the program. To calculate this, AIWC collects a frequency distribution of all non-register memory accesses by all threads in the target kernel. Using the collected frequency distribution, AIWC calculates 10 separate local memory address entropy (LMAE) values according to increasing number of least significant bits (LSB) skipped using
	%in the following fashion. The information entropy of the collection of memory addresses accessed, after dropping $n$ LSBs and accounting for the number of memory accesses performed to each address is counted as the $n$-bits skipped LMAE. Given the frequency distribution of memory addresses accessed by the program, 
	the explicit formula for the $n$-bits skipped LMAE:
	
	\begin{equation}
	LMAE_{n-bits} = \sum_{a \in A_n}p_a \log_2(p_a^{-1})
	\end{equation}
	
	\begin{itemize}
		\item $A_n$ is the set of all addresses accessed after skipping $n$ LSBs of each address.
		\item $p_a := \frac{\#access_a}{\#access_{total}}$ is the probability (calculated as relative frequency) at which each memory address is accessed.
	\end{itemize}
	
	LMAE measures the locality of memory accesses performed over the full execution of a program. A steeper drop in entropy with increasing number of bits may correlate to more localized memory accesses over the program's execution.
	
	Limitations of the memory footprint and local memory address entropy values as memory access pattern metrics are further discussed by this work. %TODO: REMOVE?
	
	\subsection{Advancements in Memory Access Pattern Characterization}
	
	We provide a brief summary of past work in architecture independent program characterization and Memory Access Pattern analysis:
	
	\begin{itemize}
		\item The Microarchitecture Independent Workload Characterization Tool (MICA) \cite{hoste2007microarchitecture} was the first microarchitecture independent workload characterization tool for single threaded programs. 
		\item The Workload ISA-Independent Characterization for Applications (WIICA) \cite{shao2013isa} extends MICA to present a framework to analyse single threaded programs independent of the ISA.
		\item CuMAPz: CuMAPz \cite{kim2011cumapz} is a CUDA memory access profiling tool and the first to present metrics for CUDA codes which can be generalized to any given NVIDIA GPU.
	\end{itemize}
	
	\subsection{MICA}
	
	The MICA framework was developed by Hoste and Eeckout \cite{hoste2007microarchitecture} in response to their findings on the limitations of conventional microarchitecture dependent characteristics. Hoste and Eeckout discovered that performance counter based approaches to profiling codes often struggled in finding underlying program features that map to improved or worsened usage of performance critical hardware features of the target architecture. The MICA framework is a holistic characterization tool, and thus collects features including instruction mix, instruction-level parallelism, register traffic, data stream strides and branch predictability.
	
	Of these metrics, data stream strides are of particular interest in memory access pattern profiling. MICA's stride length metric measures the distance between consecutive memory accesses in a single threaded application. For CPU architectures running single threaded applications, this metric correlates to the spatial locality of memory accesses -- a measure of how closely bunched are memory access in nearby times. This is directly correlated to cache reuse rates, critical to code performance on CPUs \cite{inteloptimisation}. %Intel optimization manual.
	
	The MICA approach was tailored for single-threaded applications as the metrics collected rely heavily on Pin instrumentation \cite{luk2005pin}. As such, MICA is unsuited to analysing conventional supercomputing workloads with heavy use of parallelism.

	\subsection{CuMAPz}
	
	Kim and Shrivastava \cite{kim2011cumapz} present CuMAPz, a CUDA memory access pattern analysis tool to guide NVIDIA GPU optimizations. CuMAPz focuses on the problem of improving CUDA application performance using NVIDIA memory-based optimizations. CuMAPz analyses CUDA codes structurally and simulates code execution on the memory hierarchy of specific NVIDIA GPU models.
	
	During the simulated run of the target code, CuMAPz records all memory accesses in various buffers to simulate the global and shared memories on NVIDIA GPUs. Using this detailed simulation data, CuMAPz can estimate the performance critical (i) shared memory data reuse profit, (ii) profit from coalesced access (iii) memory channel skew cost and (iv) bank conflict cost characteristics of the target code.
	
	The simulation environment described in CuMAPz and the attached analysis framework is highly specific to CUDA enabled GPUs. Replicating the CuMAPz framework for all target architectures is challenging. However, CuMAPz is an interesting simulator from the standpoint of this paper's work since it adheres to the core parts of NVIDIA GPUs' memory models in its analysis, while allowing the user to specify their GPU model specific hardware information.
	
	Our approach is an architecture independent analysis of memory access patterns that provides metrics correlating to similar performance critical memory access optimizations as CuMAPz. We aim to further the state of the art by providing a framework to guide developers in optimizing OpenCL codes for any given target architecture. To the best our knowledge, none of the previous works present a set of performance metrics that accurately characterize memory access patterns of parallel applications independent of the target architecture.
	
	\section{Methodology} \label{method}
	
	To provide memory access pattern metrics that represent vendor recommended optimizations on GPUs, we improved AIWC by adding a new metric: relative local memory usage. This measures the proportion of all memory accesses from the symbolic execution of the kernel that occurred to memory allocated as \texttt{\_\_local}. On GPUs, this memory address space is mapped to fast on-chip shared memory.
	
	Relative local memory usage is an example of a metric that is useful to measure performance critical access patterns on some architectures such as GPUs, and not others, such as CPUs. CPUs do not typically have a notion of user controlled on-chip memory shared between hardware threads such as NVIDIA GPUs' shared memory. This is a natural consequence of programming for a heterogeneous system. Specific code patterns may translate to performance improvements only on certain hardware.
	
	In the original AIWC tool \cite{beau_johnston_2017_1134175}, global and local memory address entropy (MAE) were calculated using physical addresses of memory used by the Oclgrind simulator back-end of AIWC. This caused irregularities in entropy calculations across multiple runs of the same simulation. We improved the calculation of memory address entropy by using \textit{virtual addresses} to calculate MAE values using an abstract ideal address space on which all memory accesses by the kernel occur. This allows AIWC to accurately abstract over the hardware and ISA-specific differences in memory layouts across the diverse hardware targets.
		
	\section{Results} \label{results}
	
	\begin{figure*}[h!]
		\centering
		\subfloat{
			\centering
			\begin{tikzpicture}
			\begin{axis}[symbolic x coords={simple,coalA,coalAB,coalABT,alignABT},
			xtick={simple,coalA,coalAB,coalABT,alignABT},
			xticklabel style={text height=2ex},
			ymin=0,
			ylabel={Execution time ($\mu s$)}, xlabel={Kernel},
			ylabel style={at={(axis description cs:0.1,.5)},anchor=south},
			legend entries={$N=80\ \ \ \ $,$N=256\ \ $},
			legend style={at={(0.6,0.45)},anchor=west}
			]
			
			\addplot[mark=*] coordinates {
				(simple,27.79)
				(coalA,16.36)
				(coalAB,17.02)
				(coalABT,16.34)
				(alignABT,30.21)
			};
			\addplot[mark=star] coordinates {
				(simple,319.71)
				(coalA,70.12)
				(coalAB,73.60)
				(coalABT,65.27)
				(alignABT,61.50)
			};	
			\end{axis}
			\end{tikzpicture} 
		}
		\subfloat{
			\begin{tikzpicture}
			\begin{axis}[symbolic x coords={simple,coalA,coalAB,coalABT,alignABT},
			xtick={simple,coalA,coalAB,coalABT,alignABT},
			xticklabel style={text height=2ex},
			ymin=0,
			ylabel={Execution time ($\mu s$)}, xlabel={Kernel},
			ylabel style={at={(axis description cs:0.1,.5)},anchor=south},
			legend entries={$N=1408$,$N=2048$},
			legend style={at={(0.6,0.45)},anchor=west}
			]
			
			\addplot[mark=triangle*] coordinates {
				(simple,46901.35)
				(coalA,8948.96)
				(coalAB,9237.5)
				(coalABT,5307)
				(alignABT,5272)
			};
			\addplot[mark=square] coordinates {
				(simple,130601.41)
				(coalA,28722.51)
				(coalAB,27169.72)
				(coalABT,16179.03)
				(alignABT,16071.90)
			};	
			\end{axis}
			\end{tikzpicture} 
		}
		\caption{NVIDIA Tesla P100 Runtime performance of section \ref{motivating example} codes averaged over 100 runs}
		\label{fig: matmul runtime}
	\end{figure*}

	Figure \ref{fig: matmul runtime} shows that across varying problem sizes, the vendor recommended optimizations to the matrix multiplication code lead to increased performance. Note that a matrix size of 80 is small -- overheads attached to optimization techniques may be causing the observed decrease in performance as some optimizations are performed.

	\begin{table*}[h!]
	\centering
	\begin{tabular}[t]{lrrrrr}
		\toprule
		& simple & coalescedA & coalescedAB & coalescedABT & alignedABT \\ \midrule 
		Total memory footprint        & 196608 & 196608     & 196608      & 196608       & 196608     \\ %\hline
		90\% Memory Footprint         & 118196 & 56176      & 489         & 489          & 489        \\ %\hline
		Global MAE                    & 17.02  & 13.18      & 9.78        & 9.78         & 9.78       \\ %\hline
		LMAE \#bits=3                 & 16.02  & 12.18      & 8.78        & 8.78         & 8.78       \\ %\hline
		LMAE \#bits=10                & 9.02   & 5.18       & 1.78        & 1.78         & 1.78       \\ %\hline
		Relative Local Memory Usage   & 0      & 49.91    & 94.28       & 94.28        & 94.28      \\ \bottomrule
	\end{tabular}
	\caption{Selection of AIWC\cite{beauaiwc} metrics for 256 $\times$ 256 matrix multiplication}
	\label{matmul aiwc table}
	\end{table*}

	Table \ref{matmul aiwc table} summarizes AIWC memory metrics collected for each of the matrix multiply kernels in section \ref{motivating example}. Note that only two LMAE values are shown for brevity. We now analyse the effectiveness of AIWC metrics in profiling the NVIDIA recommended memory optimizations applied to the matrix multiplication kernel.
	
	\textit{Relative local memory usage}: As reliance on NVIDIA GPUs' shared memory increases in each kernel from \texttt{simpleMultiply} to \texttt{coalescedAB}, we find that the ratio of OpenCL local memory usage increases as expected.
	
	\textit{Global and local MAE}: Entropy measurements decrease from \texttt{simpleMultiply} to \texttt{coalescedAB}. This is explained by the optimizations performed incrementally reducing accesses to matrix $A$ and $B$, and instead performing the bulk of computations on smaller tiles in on-chip shared memory. We observe an almost completely uniform distribution of memory accesses in \texttt{simpleMultiply}, where the program makes $N$ loads to each element of $A$ and $B$ with $N$ the dimension of the matrices. The frequency distribution of memory addresses accessed become increasingly non-uniform as we perform less accesses to matrices $A$ and $B$ and offset this by increasing the frequency of accesses to smaller, more localized shared memory buffers. The non-uniformity of relative frequency with which each memory cell is accessed by the program translates directly to decreases in local and global memory entropy values as reliance on small shared memory buffers increases from \texttt{simpleMultiply} to \texttt{coalescedAB}.
	
	\textit{Memory Footprint}: Similar to trends in global and local MAE, we find that the ratio of 90\% memory footprint to total memory footprint decreases from $60.12\%$ for \texttt{simpleMultiply} to $0.25\%$ (\texttt{coalescedAB}). Increased utilization of shared memory in the optimized kernels means that the shared memory buffers make up a greater proportion of total memory accesses in the program. As the shared memory buffers are small and reused within a workgroup, the memory footprint of the shared memory buffers is also smaller. 
	
	AIWC's metrics strongly reward optimizations that tend to localize memory accesses. Shared memory buffers are typically smaller than global memory arrays when programming for GPUs due to hardware limitations on sizes of shared memory buffers \cite{cudamanual}. However, the metrics currently measured by AIWC do not have a direct causal relation to code patterns that optimize memory accesses on GPUs. The proposed relative local memory usage metric is the first to correspond to a recommended optimization strategy of using fast on-chip shared memory. Further, we find that all current AIWC metrics do not measure any sizeable difference between \texttt{coalescedAB}, \texttt{coalescedABT} and \texttt{alignedABT} codes. We address the root cause of this -- a lack of temporal information about memory accesses, in the next section.%TODO READ THIS SECTION
	
	\section{Discussion} \label{discussion}
	
	AIWC metrics are inherently lossy. Given the set of metrics calculated for an unknown kernel, we can not reconstruct the kernel based on these metrics. Specifically to memory access pattern analysis, the calculation of memory address entropy of a kernel relies only on the frequency distribution of memory accesses to all addresses accessed by the kernel. We observe that calculation of memory address entropy does not make use of temporal information. The order of sequential memory accesses performed by each thread, as well as addresses requested in parallel by multiple threads in an OpenCL thread group, are both vital in accurately characterising parallel codes.
	
	We propose a new architecture independent metric to measure memory access patterns of parallel programs. The proposed metric is inspired by CuMAPz' direct approaches to measuring optimization specific characteristics of CUDA codes.
	
	AIWC currently collects a list of all memory accessed by each thread of execution. In the OpenCL programming model, threads within thread groups execute the same code and are allowed to cooperate on \textit{local memory} addresses. We can group together threads by their work groups to align histories of memory accesses of threads in a group to analyse memory accesses performed by thread groups at each logical time step in the symbolic execution of the code. We argue that analysing the accesses occuring at the same logical time step is an accurate, conceptually sound method of predicting the extent of memory access coalescing and bank conflicts we are likely to find upon executing the code on a GPU.
	
	The precise definition of the proposed metric is provided in the following section.
	
	\subsection{A Parallel Spatial Locality Metric}
	
		\begin{figure*}[h!]
		\centering
		\begin{tikzpicture}
		\begin{axis}[symbolic x coords={0,1,2,3,4,5,6,7,8,9,10},
		width=0.7\textwidth,
		height=0.5\textwidth,
		xtick={0,1,2,3,4,5,6,7,8,9,10},
		xticklabel style={text height=2ex},
		ymin=0,
		ylabel={$n$-bits dropped Parallel Spatial Locality}, xlabel={\# of bits skipped},
		ylabel style={at={(axis description cs:0.05,.5)},anchor=south},
		legend entries={\texttt{simpleMultiply},\texttt{coalescedAMultiply},
			\texttt{coalescedAB}, \texttt{coalescedABT}, \texttt{alignedABT}},
		legend style={at={(0.55,0.75)},anchor=west}
		]
		
		\addplot[mark=*] coordinates {
			(0, 4.01)
			(1,3.51)
			(2,3.01)
			(3,2.50)
			(4,2.00)
			(5,2.00)
			(6,2.00)
			(7,2.00)
			(8,2.00)
			(9,1.5)
			(10,1.00)
		};
		
		
		\addplot[mark=star] coordinates {
			(0,4.24)
			(1,3.71)
			(2,3.18)
			(3,2.65)
			(4,2.12)
			(5,1.62)
			(6,1.12)
			(7,0.62)
			(8,0.12)
			(9,0.09)
			(10,0.06)
		};
		
		\addplot[mark=triangle*] coordinates {
			(0,4.45)
			(1,3.89)
			(2,3.33)
			(3,2.78)
			(4,2.23)
			(5,1.73)
			(6,1.23)
			(7,0.73)
			(8,0.23)
			(9,0.17)
			(10,0.11)
		};
		
		\addplot[mark=square] coordinates {
			(0,4.45)
			(1,3.45)
			(2,2.45)
			(3,1.45)
			(4,0.45)
			(5,0.40)
			(6,0.34)
			(7,0.28)
			(8,0.23)
			(9,0.17)
			(10,0.11)
		};
		
		\addplot[mark=o] coordinates {
			(0,4.45)
			(1,3.45)
			(2,2.45)
			(3,1.45)
			(4,0.45)
			(5,0.40)
			(6,0.34)
			(7,0.28)
			(8,0.23)
			(9,0.17)
			(10,0.11)
		};
		\end{axis}
		\end{tikzpicture}
		\caption{Calculated parallel spatial locality metric for matrix multiply kernels for 256 $\times$ 256 matrix multiplication}
		\label{fig: matmul parallel spatial locality}
	\end{figure*}
	
	There are three steps involved in generating an AIWC metric: \textit{recording}, \textit{calculating} and \textit{summarising} data collected from the symbolic execution of the kernel under inspection.
	
	\textit{Record}: we first record memory accesses performed by each thread in an OpenCL thread group as described above to achieve a global ordering of all memory accesses performed in a thread group. This ordering is collected in the form of logical timestamps ($t_0 .. t_{last}$) at which memory accesses occur.
	
	\textit{Calculate}: for each timestamp $t = t_0 .. t_{last}$, calculate the n-bits dropped entropy of memory addresses accessed by all threads in a work group within the timestamp $t$. Here $n$ can range between 1 and 10 as was the case for $LMAE$.
	
	\textit{Summarize}: average the collected entropy values across all the timestamps to calculate the parallel spatial locality metrics for one thread group. We then average the n-bits dropped entropy summaries across thread groups to obtain the \textit{n-bits dropped parallel spatial locality metrics} for the kernel's execution.
	
%	\begin{equation} \label{entropyaverage}
%		\log_2(\frac{\sum_{t = t_0}^{t_{last}} 2^{E_{n,t}}}{\#{timestamps}})
%	\end{equation} 
	
%	With $E_{n,t}$ the n-bits dropped entropy at timestamp $t$.

	The proposed metric is a parallel computing analogue for MICA's data stride metric that measures the distance between consecutive data accesses in a single threaded environment. 
	In parallel programs, to accurately measure spatial locality of accesses, we must consider memory accesses performed by multiple threads in a close temporal scope. 
	The proposed metric calculates the locality of accesses in each time step of the program's execution and steeper drop-offs in $n$-bits dropped parallel spatial locality scores will be observed in programs that access nearby memory addresses within the same timestamp.
	Such programs will perform better on GPUs, as they will make better use of both global memory access coalescing and shared memory bank structures.
	To a lesser extent, the proposed metric captures performance-critical memory access patterns on CPUs, as pulling a single cacheline from global memory services the threads running on all CPU cores. %TODO: Josh, Beau -- Please check this paragraph.
	
	In figure \ref{fig: matmul parallel spatial locality} we see theoretical calculations for the proposed parallel spatial locality metric for each of the matrix multiplication kernels from section \ref{motivating example}. In particular we observe that the \texttt{coalescedABT} and \texttt{alignedABT} kernels have the steepest drop-offs in entropy as the number of bits skipped is increased, which correlates to better locality of parallel memory accesses. It is expected for these kernels to exhibit better parallel spatial locality than \texttt{simpleMultiply}, as \texttt{coalescedABT} and \texttt{alignedABT} make use of shared memory, where accesses tend to be localized simply due to the small size of shared on-chip memory typically available on GPUs. Further we find that the proposed metric successfully distinguishes between the \texttt{coalescedAB} and \texttt{coalescedABT} kernels. It accurately depicts a steeper drop-off for the more optimized \texttt{coalescedABT} kernel, where a larger proportion of parallel memory accesses make better use of the memory bank structure of GPU shared memory than all previous kernels. This is a significant improvement over the state-of-the-art AIWC metrics in characterising how codes localize shared memory accesses to better use the hardware provided.
	
	\section{Results}
	
	The Extended OpenDwarfs benchmark suite is a set of OpenCL workload classified according to the computation patterns or Dwarfs. First presented in 2006, the Dwarfs categorize 
	We present the results of running the AIWC tool on the Extended OpenDwarfs benchmark suite \cite{opendwarfs2017base,extendedopendwarfs}.
	
	
	% As all kernels access memory on word (32-bit) boundaries, there is no effect in dropping upto two bits in the PSL metric...
	\begin{figure*}[h!]
		\centering
		\begin{tikzpicture}
		\begin{axis}[symbolic x coords={0,1,2,3,4,5,6,7,8,9,10},
		width=0.7\textwidth,
		height=0.5\textwidth,
		xtick={0,1,2,3,4,5,6,7,8,9,10},
		xticklabel style={text height=2ex},
		ymin=0,
		ylabel={$n$-bits dropped Parallel Spatial Locality}, xlabel={\# of bits skipped},
		ylabel style={at={(axis description cs:0.05,.5)},anchor=south},
		legend entries={\texttt{GEM}, \texttt{NW*}, \texttt{SRAD Kernel 1},\texttt{SRAD Kernel 2},
			\texttt{CSR}, \texttt{BFS*}, \texttt{LUD Diagonal}, \texttt{LUD Internal}, \texttt{LUD Perimeter}, \texttt{TDM}},
		legend style={at={(0.55,0.75)},anchor=west}
		]
		
		
		\addplot[mark=*] coordinates {
			(0, 0.1139)
			(1, 0.1139)
			(2, 0.1139)
			(3, 0.1139)
			(4, 0.0989)
			(5, 0.08402)
			(6, 0.06914)
			(7, 0.05431)
			(8, 0.03938)
			(9, 0.02442)
			(10, 0.0124)
		};
		
		
		\addplot[mark=star] coordinates {
			(0, 2.175)
			(1, 2.175)
			(2, 2.175)
			(3, 2.175)
			(4, 2.175)
			(5, 2.175)
			(6, 2.175)
			(7, 2.175)
			(8, 2.175)
			(9, 2.175)
			(10, 2.175)
		};
		
		\addplot[mark=*] coordinates {
			(0, 7.232)
			(1, 7.232)
			(2, 7.232)
			(3, 7.232)
			(4, 6.351)
			(5, 5.461)
			(6, 4.570)
			(7, 3.678)
			(8, 3.648)
			(9, 3.633)
			(10, 3.625)
		};
		
		
		\addplot[mark=star] coordinates {
			(0, 7.098)
			(1, 7.098)
			(2, 7.098)
			(3, 7.098)
			(4, 6.223)
			(5, 5.344)
			(6, 4.464)
			(7, 3.583)
			(8, 3.567)
			(9, 3.559)
			(10, 3.556)
		};
		
		\addplot[mark=triangle*] coordinates {
			(0, 9.605)
			(1, 9.605)
			(2, 9.605)
			(3, 9.605)
			(4, 9.478)
			(5, 9.293)
			(6, 9.049)
			(7, 8.761)
			(8, 8.447)
			(9, 8.12)
			(10,7.233)
		};
		
		\addplot[mark=square] coordinates {
			(0,4.406)
			(1,4.406)
			(2,4.406)
			(3,4.406)
			(4,4.361)
			(5,4.273)
			(6,4.135)
			(7,3.941)
			(8,3.689)
			(9,3.382)
			(10,3.029)
		};
		
		\addplot[mark=o] coordinates {
			(0,1.548)
			(1,1.548)
			(2,1.548)
			(3,1.548)
			(4,1.305)
			(5,1.092)
			(6,0.9385)
			(7,0.8796)
			(8,0.8796)
			(9,0.8796)
			(10,0.8796)
		};
		\end{axis}
		\end{tikzpicture}
		\caption{Parallel spatial locality metric for selected OpenDwarfs benchmark kernels}
		\label{fig: opendwarfs parallel spatial locality}
	\end{figure*}
	\subsection{N-body methods: GEM}
	
	% TODO
	The OpenDwarfs benchmark GEM computes the electrostatic potential of a biomolecule by calculating the sum of charges contributed by all atoms in the biomolecule at each specific surface vertex.
	This is an embarrassingly parallel problem. Each OpenCL work-item operates on a single surface vertex, finding the electrostatic potential generated by looping through every atom in the biomolecule in a global order. 
	The computation pattern is highly regular and memory accesses are perfectly synchronized. Atom data is accessed consecutively, with all work-items simultaneously accessing each single atom's data.
	The parallel spatial locality metric reflects this pattern of efficient memory utilization (single loads from global memory servicing all OpenCL work-items). The recorded parallel spatial locality approaches the theoretical limit of 0 (0.0124 at 10 bits dropped). This indicates that almost all memory accesses made by the OpenCL kernel are perfectly synchronized between OpenCL threads.
	
	\subsection{Dense Linear Algebra: Lower-upper decomposition (LUD)}
	
	LUD in OpenDwarfs is a program to decompose an input $N\times N$ matrix as the product of one lower and one upper diagonal matrix. LUD is a Memory access patterns in a dense linear algebra workload such as LUD are typically highly regular and deterministic for each OpenCL work item, based on the the matrix dimension and offset parameters. The OpenDwarfs implementation of LUD \cite{opendwarfs2017base} splits the LUD computation into three kernels: LUD perimeter and diagonal kernels spawn work-items in a single work dimension while LUD internal performs work in both dimensions of the input matrix.
	
	LUD perimeter and diagonal partially benefit from memory access coalescing, for the lines of code where all the work-items access contiguous memory along a row of the input matrix. However, when threads parallelly access a column of the input matrix, multiple memory requests are made as addresses accessed are too distant to be coalesced into a single memory transaction on GPUs. This is reflected in the slow drop in parallel spatial locality for LUD perimeter and diagonal kernels.
	
	LUD internal %TODO: 2Dimensional work -- better parallelism
	
	%The use of creates imbalanced workload and divergent control flow within work-items in each kernel iteration. While the presence of conditional statements cause some thread divergence in the LUD diagonal kernel, the use of barriers following conditional statements synchronizes the threads. LUD diagonal and perimeter kernels , while LUD.
	
	...  %TODO: Divergence in the kernels. Make a diagram/code simplification for LUD.
	
	\subsection{Dynamic Programming: Needleman-Wunsch (NW)}
	
	Needleman-Wunsch is a dynamic programming algorithm used to perform protein sequence alignment by identifying the similarity level between two strings of Amino acids. Elements in a matrix are computed, with each element dependent on its west, north and north-west neighbours. This dependency enforces a wavefront computation pattern, travelling along the main diagonal of the matrix. Each iteration of the kernels computes over an antidiagonal of the matrix, starting at its top left corner and finishing at its bottom right corner.
	
	In particular, the wavefront pattern of computations causes each work-item to request distant memory addresses in a parallel fashion. Thus, parallel memory requests into the input matrix prohibit locality. We note the lack of any dropoff in parallel spatial locality as the number of bits dropped increases. This rightly indicates that memory addresses accessed at each logical timestamp are very distant. On GPUs this will translate to poor utilization of both memory access coalescing and caching. This trend in the parallel spatial locality metric suggests that a possible improvement for GPU performance would be to load blocks of the input matrix into on-chip local memory to reduce the number of global memory requests. 
	
	\subsection{Structured Grids: Speckle Reducing Anisotropic Diffusion (SRAD)}
	
	SRAD removes locally correlated noise from images by following a repeated grid update computation pattern. Conditional statements in the code cause thread divergence, potentially within a work-group, to handle boundary conditions. These boundaries constitute a small portion of the executed work-items, especially on larger data-sets and so the effective thread divergence is minimal. Thus, memory access patterns in SRAD are statically determined and relatively localized. The observed rapid drop-off in parallel spatial locality of the SRAD kernels (figure \ref{fig: opendwarfs parallel spatial locality}) is due to the highly localized nature of parallel memory accesses. At each point in the kernels' memory access profile, each work-item $(i,j)$ in an OpenCL work-group accesses the $(i,j)^{th}$ elements of various matrices. The sequential memory access pattern is non-linear since different matrices are accessed consecutively by the kernel, prohibiting ideal caching. However, memory requests made parallelly are highly localized, allowing memory access coalescing on GPUs, greatly reducing the number of memory requests made on each line of the kernel code on GPUs. Thus while cache hit rates are typically low on this benchmark, particularly on GPUs \cite{krommydas2016opendwarfs}, GPUs can hide the latency of global memory accesses through coalescing.
	
	\subsection{Graph Traversal: BFS}
	
	Graph traversal algorithms require pointer chasing operations to traverse nodes of a graph and perform calculations. The Breadth First Search implemented in OpenDwarfs calls OpenCL kernels to traverse nodes immediately connected to the list of nodes at each depth starting from the root node. BFS is characterized by an imbalanced workload per kernel launch depending on the degree of the nodes being operated on -- with only a proportion of launched nodes performing meaningful work. As such the AIWC features collected for each kernel invocation vary significantly. The parallel spatial locality metric collects the entropy of memory accesses at each time step, and workload imbalances are dealt with by averaging entropy scores across all the time steps in the execution of an OpenCL work-group. 
	
	The memory access patterns in BFS are irregular. Work-items fetch discontinuous memory locations attributed to any particular node in the graph, depending on the connectivity of the node they operate on. The program structure involves multiple levels of pointer-chasing and thus the precise memory address accessed are runtime dependent. This leads to poor parallel spatial locality. Thus, we see a slow dropoff in parallel spatial locality for BFS.
	
	\subsection{Sparse Linear Algebra: CSR}
	
	Compressed Sparse Row Matrix-Vector Multiplication (CSR) computes the sum of each of a matrix's row's elements after it is multiplied by a given vector. The matrix is stored in a compressed row storage sparse matrix format, which is very efficient for storage when the number of zero elements is far greater than the number of non-zero elements. Only non-zero elements of each row of a matrix are stored in $Ax$, along with separate arrays $Aj,\ Ap$ indicating the position of each non-zero element in the matrix. Figure \ref{?} depicts the sparse matrix format of storage for a $4\times4$ matrix.
	
	In this particular implementation, a single OpenCL work-item is assigned to compute over each row of the input sparse matrix. Similar to BFS, memory access patterns are runtime-dependent, since the locations of matrix data read by each thread are dependent on the number and position of non-zero values in the sparse-matrix, decided by the values in $Aj$ and $Ap$. This pattern of indirect addressing is typical of applications in the Spare Linear Algebra Dwarf, which severely hinders locality of memory accesses performed. The parallel spatial locality metric reflects this trend. Figure \ref{fig: opendwarfs parallel spatial locality} shows the very gradual decline in parallel spatial locality as the number of bits dropped is increased.
	
	\subsection{Finite State Machine: Temporal Data Mining (TDM)}
	
	%TODO
	
	\section{Conclusions and Future Work} \label{future work}
	
	To the best of our knowledge this work is the first to critically examine architecture independent methods to measure memory access patterns and guide hardware-specific optimization. We implemented and justified the addition of relative local memory usage to AIWC in our steps to characterize memory-based GPU code optimizations. We have also proposed the methodology to implement a new parallel spatial locality metric to AIWC. Upon implementation, our work would be the first to measure memory access patterns of parallel codes in an architecture-independent, easily interpreted manner.
	%TODO UPDATE IN FUTURE
	
	Our proposed parallel spatial locality metric may also correlate to some memory-based optimization strategies for CPUs. Future work would apply the approach followed by this paper to CPU and FPGA architectures to evaluate the viability of an architecture independent characterization of memory access patterns in codes targeted to these architectures.
	
	Future work will provide a concrete implementation of this new parallel spatial locality metric in the AIWC framework. It is then feasible to test these new metrics across a larger set of GPU targeted OpenCL codes. This will allow a critical examination of the effectiveness of both proposed metrics in accurately profiling memory access patterns of these diverse codes.

	\bibliographystyle{plain}
	\bibliography{bib/bibliography.bib}
	
	\begin{appendix}
		
		\section{\texttt{simpleMultiply} kernel} \label{simpleMultiply}
		
		\begin{lstlisting}
		__kernel void simpleMultiply(__global float *A,
				__global float *B, 
				__global float *C, 
				int N)
		{
			const int globalRow = get_global_id(0); // Row ID of C (0..N-1)
			const int globalCol = get_global_id(1); // Col ID of C (0..N-1)
			// Compute a single element of C (loop over K)
			float acc = 0.0f;
			for (int k = 0; k < N; ++k) {
				acc += B[k * N + globalCol] * A[globalRow * N + k];
		`	}
			// Store the result
			C[globalRow * N + globalCol] = acc;
		}
		
		\end{lstlisting}
		
		\section{\texttt{coalescedAMultiply} kernel} \label{coalescedAMultiply}

			
		\begin{lstlisting}
		__kernel void coalescedAMultiply(
				const __global float* A,
				const __global float* B,
				__global float* C,
				const int N)
		{
			__local float aTile[TILE_DIM][TILE_DIM];
			
			const int localRow = get_local_id(0);
			const int localCol = get_local_id(1);
			
			const int globalRow = get_global_id(0);
			const int globalCol = get_global_id(1);
			
			__private float sum = 0.0f;
			
			const int numTiles = N / TILE_DIM;
			__private const int tiledRow = globalRow*N+ localCol;
			for (int i = 0; i < numTiles; i++) {
				aTile[localRow][localCol] = A[tiledRow+i*TILE_DIM];
				barrier(CLK_LOCAL_MEM_FENCE);
				for (int k = 0; k < TILE_DIM; k++) {
					sum += aTile[localRow][k] * B[(i*TILE_DIM+k)*N+globalCol];
				}
				barrier(CLK_LOCAL_MEM_FENCE);
			}
			C[globalRow*N+globalCol] = sum;
		}
		\end{lstlisting}

		
		\section{\texttt{coalescedAB} kernel} \label{coalescedABMultiply}
			
		\begin{lstlisting}
		__kernel void coalescedAB(
				const __global float* A,
				const __global float* B,
				__global float* C,
				const int N) {
			__local float ASub[TILE_DIM][TILE_DIM];
			__local float BSub[TILE_DIM][TILE_DIM];    
			
			const int localRow = get_local_id(0);
			const int localCol = get_local_id(1);
			const int globalRow = get_global_id(0);
			const int globalCol = get_global_id(1);
			
			float acc = 0.0f;
			const int numTiles = N/TILE_DIM;
			
			for (int i = 0; i < numTiles; i++) {
				const int tiledRow = globalRow*N+i*TILE_DIM + localCol;
				const int tiledCol = globalCol + (TILE_DIM*i + localRow)*N;
				ASub[localRow][localCol] = A[tiledRow];
				BSub[localRow][localCol] = B[tiledCol];
				
				barrier(CLK_LOCAL_MEM_FENCE);
				
				for (int k=0; k<TILE_DIM; k++) {
					acc += ASub[localRow][k] * BSub[k][localCol];
				}
				
				barrier(CLK_LOCAL_MEM_FENCE);
			}
			C[globalRow*N + globalCol] = acc;
		}
		\end{lstlisting}
	\end{appendix}
	
\end{document}